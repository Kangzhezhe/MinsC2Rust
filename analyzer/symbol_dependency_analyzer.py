#!/usr/bin/env python3
"""
Cä»£ç ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨
åŸºäºtree-sitter ASTå’Œc_project_analysis.jsonæ„å»ºç¬¦å·ä¾èµ–å›¾
"""

import json
import os
import tree_sitter_c as ts_c
from tree_sitter import Language, Parser, Node
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum
import re
from pathlib import Path

try:  # å…¼å®¹è„šæœ¬ç›´æ¥æ‰§è¡Œä¸åŒ…å†…å¯¼å…¥
    from config import get_output_dir
except ImportError:  # pragma: no cover
    from .config import get_output_dir

_DEFAULT_OUTPUT_DIR = get_output_dir()
_DEFAULT_ANALYSIS_PATH = _DEFAULT_OUTPUT_DIR / "c_project_analysis.json"
_DEFAULT_DEPENDENCIES_PATH = _DEFAULT_OUTPUT_DIR / "symbol_dependencies.json"

class SymbolType(Enum):
    """ç¬¦å·ç±»å‹æšä¸¾"""
    FUNCTION = "functions"
    STRUCT = "structs"
    TYPEDEF = "typedefs"
    VARIABLE = "variables"
    MACRO = "macros"
    ENUM = "enums"

class DependencyType(Enum):
    """ä¾èµ–ç±»å‹æšä¸¾"""
    FUNCTION_CALL = "function_call"      # å‡½æ•°è°ƒç”¨
    TYPE_REFERENCE = "type_reference"    # ç±»å‹å¼•ç”¨
    VARIABLE_USE = "variable_use"        # å˜é‡ä½¿ç”¨
    MACRO_USE = "macro_use"              # å®ä½¿ç”¨
    ENUM_USE = "enum_use"                # æšä¸¾ä½¿ç”¨
    STRUCT_MEMBER = "struct_member"      # ç»“æ„ä½“æˆå‘˜è®¿é—®

@dataclass
class Symbol:
    """ç¬¦å·ä¿¡æ¯"""
    name: str
    symbol_type: SymbolType
    file_path: str
    start_line: int = 0
    end_line: int = 0
    definition: str = ""
    
    def __hash__(self):
        return hash((self.name, self.symbol_type.value, self.file_path))
    
    def __eq__(self, other):
        if not isinstance(other, Symbol):
            return False
        return (self.name == other.name and 
                self.symbol_type == other.symbol_type and 
                self.file_path == other.file_path)

@dataclass
class Dependency:
    """ä¾èµ–å…³ç³»ï¼ˆåŒ…å«ä¾èµ–å‘ç”Ÿä½ç½®çš„èµ·æ­¢è¡Œå·ï¼Œ1-based æ–‡ä»¶è¡Œå·ï¼‰"""
    source_symbol: Symbol
    target_symbol: Symbol
    dependency_type: DependencyType
    start_line: int = 0
    end_line: int = 0

@dataclass
class SymbolDependencyGraph:
    """ç¬¦å·ä¾èµ–å›¾"""
    symbols: Dict[str, Symbol] = field(default_factory=dict)
    dependencies: List[Dependency] = field(default_factory=list)
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        self._dependency_set: Set[str] = set()  # ç”¨äºæ£€æµ‹é‡å¤ä¾èµ–
    
    def add_symbol(self, symbol: Symbol):
        """æ·»åŠ ç¬¦å·"""
        key = f"{symbol.name}:{symbol.symbol_type.value}:{symbol.file_path}"
        self.symbols[key] = symbol
    
    def add_dependency(self, dependency: Dependency):
        """æ·»åŠ ä¾èµ–å…³ç³»ï¼ˆè‡ªåŠ¨å»é‡ï¼‰"""
        # åˆ›å»ºä¾èµ–å…³ç³»çš„å”¯ä¸€æ ‡è¯†ï¼ˆä¸åŒ…æ‹¬å…·ä½“çš„ç¬¦å·å®ä¾‹å’Œä½ç½®ï¼‰
        dep_signature = (
            dependency.source_symbol.name,
            dependency.source_symbol.symbol_type.value,
            dependency.source_symbol.file_path,
            dependency.target_symbol.name,
            dependency.target_symbol.symbol_type.value,
            dependency.target_symbol.file_path,
            dependency.dependency_type.value
        )
        
        # åªæ·»åŠ ä¸é‡å¤çš„ä¾èµ–å…³ç³»
        dep_key = str(dep_signature)
        if not hasattr(self, '_dependency_set'):
            self._dependency_set = set()
            
        if dep_key not in self._dependency_set:
            self.dependencies.append(dependency)
            self._dependency_set.add(dep_key)
            return True  # æˆåŠŸæ·»åŠ 
        return False  # é‡å¤ï¼Œæœªæ·»åŠ 
    
    def get_symbol_dependencies(self, symbol_name: str, symbol_type: SymbolType = None) -> List[Dependency]:
        """è·å–æŒ‡å®šç¬¦å·çš„æ‰€æœ‰ä¾èµ–"""
        dependencies = []
        for dep in self.dependencies:
            if dep.source_symbol.name == symbol_name:
                if symbol_type is None or dep.source_symbol.symbol_type == symbol_type:
                    dependencies.append(dep)
        return dependencies
    
    def get_symbols_by_type(self, symbol_type: SymbolType) -> List[Symbol]:
        """æ ¹æ®ç±»å‹è·å–ç¬¦å·"""
        return [symbol for symbol in self.symbols.values() 
                if symbol.symbol_type == symbol_type]
    
    def get_symbol_dependents(self, symbol_name: str, symbol_type: SymbolType = None) -> List[Dependency]:
        """è·å–ä¾èµ–æŒ‡å®šç¬¦å·çš„æ‰€æœ‰ä¾èµ–å…³ç³»ï¼ˆè¢«ä¾èµ–ï¼‰"""
        dependents = []
        for dep in self.dependencies:
            if dep.target_symbol.name == symbol_name:
                if symbol_type is None or dep.target_symbol.symbol_type == symbol_type:
                    dependents.append(dep)
        return dependents
    
    def get_all_related_symbols(self, symbol_name: str, max_depth: int = 2) -> Set[str]:
        """è·å–ä¸æŒ‡å®šç¬¦å·ç›¸å…³çš„æ‰€æœ‰ç¬¦å·ï¼ˆåŒ…æ‹¬ä¾èµ–å’Œè¢«ä¾èµ–ï¼‰"""
        related = set()
        to_visit = [(symbol_name, 0)]
        visited = set()
        
        while to_visit:
            current_symbol, depth = to_visit.pop(0)
            if current_symbol in visited or depth > max_depth:
                continue
            
            visited.add(current_symbol)
            related.add(current_symbol)
            
            if depth < max_depth:
                # æ·»åŠ ä¾èµ–çš„ç¬¦å·
                deps = self.get_symbol_dependencies(current_symbol)
                for dep in deps:
                    if dep.target_symbol.name not in visited:
                        to_visit.append((dep.target_symbol.name, depth + 1))
                
                # æ·»åŠ è¢«ä¾èµ–çš„ç¬¦å·
                dependents = self.get_symbol_dependents(current_symbol)
                for dep in dependents:
                    if dep.source_symbol.name not in visited:
                        to_visit.append((dep.source_symbol.name, depth + 1))
        
        return related

class SymbolDependencyAnalyzer:
    """ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨"""
    
    def __init__(self, analysis_json_path: str):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.analysis_json_path = analysis_json_path
        self.C_LANGUAGE = Language(ts_c.language())
        self.parser = Parser(self.C_LANGUAGE)
        
        # åŠ è½½åˆ†æç»“æœ
        with open(analysis_json_path, 'r', encoding='utf-8') as f:
            self.analysis_data = json.load(f)
        
        # åˆå§‹åŒ–ä¾èµ–å›¾
        self.dependency_graph = SymbolDependencyGraph()
        
        # ç¬¦å·æ³¨å†Œè¡¨ï¼šå­˜å‚¨æ‰€æœ‰å·²çŸ¥ç¬¦å·
        self.symbol_registry: Dict[str, List[Symbol]] = {}
        
        # Cè¯­è¨€å…³é”®å­—å’Œå†…ç½®ç±»å‹ï¼Œéœ€è¦æ’é™¤
        self.c_keywords = {
            'auto', 'break', 'case', 'char', 'const', 'continue', 'default', 'do',
            'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if',
            'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static',
            'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while',
            # C99/C11 keywords
            'inline', 'restrict', '_Bool', '_Complex', '_Imaginary',
            # Common types
            'size_t', 'ssize_t', 'ptrdiff_t', 'NULL'
        }
        
        # å†…ç½®å‡½æ•°ï¼Œéœ€è¦æ’é™¤
        self.builtin_functions = {
            'malloc', 'free', 'calloc', 'realloc', 'printf', 'scanf', 'strlen',
            'strcpy', 'strcmp', 'strncmp', 'strcat', 'memcpy', 'memset', 'memcmp'
        }
    
    def build_symbol_registry(self):
        """æ„å»ºç¬¦å·æ³¨å†Œè¡¨"""
        print("æ„å»ºç¬¦å·æ³¨å†Œè¡¨...")
        
        for file_path, file_data in self.analysis_data.items():
            if not file_data.get('parse_success', False):
                continue
            
            # æ³¨å†Œå„ç§ç±»å‹çš„ç¬¦å·
            for symbol_type in SymbolType:
                symbol_list = file_data.get(symbol_type.value, [])
                for symbol_data in symbol_list:
                    symbol = self._create_symbol_from_data(symbol_data, symbol_type, file_path)
                    if symbol:
                        self.dependency_graph.add_symbol(symbol)
                        
                        # æ·»åŠ åˆ°æ³¨å†Œè¡¨
                        if symbol.name not in self.symbol_registry:
                            self.symbol_registry[symbol.name] = []
                        self.symbol_registry[symbol.name].append(symbol)
        
        print(f"ç¬¦å·æ³¨å†Œè¡¨æ„å»ºå®Œæˆï¼šå…±æ³¨å†Œ {len(self.symbol_registry)} ä¸ªç¬¦å·åç§°")
    
    def _create_symbol_from_data(self, symbol_data: dict, symbol_type: SymbolType, file_path: str) -> Optional[Symbol]:
        """ä»JSONæ•°æ®åˆ›å»ºSymbolå¯¹è±¡"""
        name = symbol_data.get('name', '')
        if not name or name in self.c_keywords:
            return None
        
        symbol = Symbol(
            name=name,
            symbol_type=symbol_type,
            file_path=file_path,
            start_line=symbol_data.get('start_line', 0),
            end_line=symbol_data.get('end_line', 0),
            definition=symbol_data.get('full_definition', '') or symbol_data.get('full_declaration', '')
        )
        
        return symbol
    
    def is_valid_symbol_reference(self, name: str, context_node: Node = None) -> bool:
        """åˆ¤æ–­ä¸€ä¸ªåç§°æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ç¬¦å·å¼•ç”¨"""
        if not name or name in self.c_keywords or name in self.builtin_functions:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—æˆ–å­—ç¬¦ä¸²å­—é¢é‡
        if name.isdigit() or (name.startswith('"') and name.endswith('"')):
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ³¨å†Œè¡¨ä¸­
        return name in self.symbol_registry
    
    def extract_dependencies_from_text(self, text: str, source_symbol: Symbol) -> List[Dependency]:
        """ä»æ–‡æœ¬ä¸­æå–ä¾èµ–å…³ç³»"""
        dependencies = []
        
        # ä½¿ç”¨tree-sitterè§£æä»£ç ç‰‡æ®µ
        try:
            tree = self.parser.parse(bytes(text, "utf8"))
            root_node = tree.root_node
            dependencies.extend(self._extract_dependencies_from_ast(root_node, text, source_symbol))
        except Exception as e:
            print(f"è§£æä»£ç ç‰‡æ®µå¤±è´¥ {source_symbol.name}: {e}")
            # å›é€€åˆ°ç®€å•çš„æ–‡æœ¬åŒ¹é…
            dependencies.extend(self._extract_dependencies_by_pattern(text, source_symbol))
        
        return dependencies
    
    def _extract_dependencies_from_ast(self, node: Node, text: str, source_symbol: Symbol) -> List[Dependency]:
        """åŸºäºASTæå–ä¾èµ–å…³ç³»"""
        dependencies = []
        local_variables = set()  # å­˜å‚¨å±€éƒ¨å˜é‡å
        
        def collect_local_variables(node: Node):
            """æ”¶é›†å±€éƒ¨å˜é‡å£°æ˜"""
            if node.type == 'declaration':
                declarator = node.child_by_field_name('declarator')
                if declarator:
                    if declarator.type == 'identifier':
                        var_name = text[declarator.start_byte:declarator.end_byte]
                        local_variables.add(var_name)
                    elif declarator.type == 'init_declarator':
                        declarator_node = declarator.child_by_field_name('declarator')
                        if declarator_node and declarator_node.type == 'identifier':
                            var_name = text[declarator_node.start_byte:declarator_node.end_byte]
                            local_variables.add(var_name)
            
            # å‚æ•°å£°æ˜
            elif node.type == 'parameter_declaration':
                declarator = node.child_by_field_name('declarator')
                if declarator and declarator.type == 'identifier':
                    var_name = text[declarator.start_byte:declarator.end_byte]
                    local_variables.add(var_name)
            
            # é€’å½’æ”¶é›†
            for child in node.children:
                collect_local_variables(child)
        
        def traverse_node(node: Node):
            # å‡½æ•°è°ƒç”¨
            if node.type == 'call_expression':
                func_node = node.child_by_field_name('function')
                if func_node:
                    if func_node.type == 'identifier':
                        func_name = text[func_node.start_byte:func_node.end_byte]
                        if self.is_valid_symbol_reference(func_name) and func_name not in local_variables:
                            dependencies.extend(self._create_dependencies_for_name(
                                func_name, source_symbol, DependencyType.FUNCTION_CALL, func_node
                            ))
                    elif func_node.type == 'field_expression':
                        # å¤„ç†ç»“æ„ä½“æˆå‘˜å‡½æ•°è°ƒç”¨ obj.func()
                        field_node = func_node.child_by_field_name('field')
                        if field_node and field_node.type == 'field_identifier':
                            field_name = text[field_node.start_byte:field_node.end_byte]
                            if self.is_valid_symbol_reference(field_name):
                                dependencies.extend(self._create_dependencies_for_name(
                                    field_name, source_symbol, DependencyType.FUNCTION_CALL, field_node
                                ))
            
            # ç±»å‹å£°æ˜å’Œè½¬æ¢
            elif node.type in ['type_identifier', 'struct_specifier', 'union_specifier', 'enum_specifier']:
                if node.type == 'type_identifier':
                    type_name = text[node.start_byte:node.end_byte]
                    if self.is_valid_symbol_reference(type_name):
                        dependencies.extend(self._create_dependencies_for_name(
                            type_name, source_symbol, DependencyType.TYPE_REFERENCE, node
                        ))
                else:
                    # struct/union/enum å…³é”®å­—åçš„æ ‡è¯†ç¬¦
                    name_node = node.child_by_field_name('name')
                    if name_node and name_node.type == 'type_identifier':
                        type_name = text[name_node.start_byte:name_node.end_byte]
                        if self.is_valid_symbol_reference(type_name):
                            dependencies.extend(self._create_dependencies_for_name(
                                type_name, source_symbol, DependencyType.TYPE_REFERENCE, name_node
                            ))
            
            # å­—æ®µè®¿é—® obj.field
            elif node.type == 'field_expression':
                field_node = node.child_by_field_name('field')
                if field_node and field_node.type == 'field_identifier':
                    field_name = text[field_node.start_byte:field_node.end_byte]
                    if self.is_valid_symbol_reference(field_name):
                        dependencies.extend(self._create_dependencies_for_name(
                            field_name, source_symbol, DependencyType.STRUCT_MEMBER, field_node
                        ))
            
            # é¢„å¤„ç†æŒ‡ä»¤ (å®ä½¿ç”¨)
            elif node.type == 'preproc_defined' or node.type == 'preproc_call':
                if node.type == 'preproc_call':
                    directive_node = node.child_by_field_name('directive')
                    if directive_node and directive_node.type == 'preproc_directive':
                        directive_name = text[directive_node.start_byte:directive_node.end_byte]
                        if self.is_valid_symbol_reference(directive_name):
                            dependencies.extend(self._create_dependencies_for_name(
                                directive_name, source_symbol, DependencyType.MACRO_USE, directive_node
                            ))
            
            # sizeof è¡¨è¾¾å¼
            elif node.type == 'sizeof_expression':
                type_node = node.child_by_field_name('type')
                if type_node:
                    if type_node.type == 'type_identifier':
                        type_name = text[type_node.start_byte:type_node.end_byte]
                        if self.is_valid_symbol_reference(type_name):
                            dependencies.extend(self._create_dependencies_for_name(
                                type_name, source_symbol, DependencyType.TYPE_REFERENCE, type_node
                            ))
                    elif type_node.type == 'parenthesized_expression':
                        inner_node = type_node.children[1] if len(type_node.children) > 1 else None
                        if inner_node and inner_node.type == 'type_identifier':
                            type_name = text[inner_node.start_byte:inner_node.end_byte]
                            if self.is_valid_symbol_reference(type_name):
                                dependencies.extend(self._create_dependencies_for_name(
                                    type_name, source_symbol, DependencyType.TYPE_REFERENCE, inner_node
                                ))
            
            # æ ‡è¯†ç¬¦å¼•ç”¨ï¼ˆæœ€é€šç”¨çš„æƒ…å†µï¼‰
            elif node.type == 'identifier':
                identifier = text[node.start_byte:node.end_byte]
                if (self.is_valid_symbol_reference(identifier) and 
                    identifier not in local_variables and 
                    not self._is_in_declaration_context(node)):
                    # æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šä¾èµ–ç±»å‹
                    dep_type = self._infer_dependency_type(node, text)
                    dependencies.extend(self._create_dependencies_for_name(
                        identifier, source_symbol, dep_type, node
                    ))
            
            # é€’å½’éå†å­èŠ‚ç‚¹
            for child in node.children:
                traverse_node(child)
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰å±€éƒ¨å˜é‡
        collect_local_variables(node)
        
        # ç„¶åéå†æŸ¥æ‰¾ä¾èµ–
        traverse_node(node)
        return dependencies
    
    def _infer_dependency_type(self, node: Node, text: str) -> DependencyType:
        """æ ¹æ®ASTèŠ‚ç‚¹ä¸Šä¸‹æ–‡æ¨æ–­ä¾èµ–ç±»å‹"""
        identifier = text[node.start_byte:node.end_byte]
        parent = node.parent
        
        if not parent:
            return DependencyType.VARIABLE_USE
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„å®
        if self._is_likely_macro(identifier):
            return DependencyType.MACRO_USE
        
        # å‡½æ•°è°ƒç”¨
        if parent.type == 'call_expression' and parent.child_by_field_name('function') == node:
            return DependencyType.FUNCTION_CALL
        
        # ç±»å‹å£°æ˜æˆ–è½¬æ¢
        if parent.type in ['type_identifier', 'primitive_type', 'cast_expression', 
                          'struct_specifier', 'union_specifier', 'enum_specifier']:
            return DependencyType.TYPE_REFERENCE
        
        # ç»“æ„ä½“æˆå‘˜è®¿é—®
        if parent.type in ['field_expression', 'field_identifier']:
            return DependencyType.STRUCT_MEMBER
        
        # å®ä½¿ç”¨ - æ£€æŸ¥æ˜¯å¦åœ¨å®è°ƒç”¨ä¸­
        if self._is_in_macro_context(node):
            return DependencyType.MACRO_USE
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ³¨å†Œè¡¨ä¸­ç¡®å®šç±»å‹
        if identifier in self.symbol_registry:
            for symbol in self.symbol_registry[identifier]:
                if symbol.symbol_type == SymbolType.FUNCTION:
                    return DependencyType.FUNCTION_CALL
                elif symbol.symbol_type == SymbolType.MACRO:
                    return DependencyType.MACRO_USE
                elif symbol.symbol_type in [SymbolType.STRUCT, SymbolType.TYPEDEF]:
                    return DependencyType.TYPE_REFERENCE
                elif symbol.symbol_type == SymbolType.ENUM:
                    return DependencyType.ENUM_USE
        
        # é»˜è®¤ä¸ºå˜é‡ä½¿ç”¨
        return DependencyType.VARIABLE_USE
    
    def _is_in_declaration_context(self, node: Node) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨å˜é‡å£°æ˜ä¸Šä¸‹æ–‡ä¸­"""
        parent = node.parent
        while parent:
            if parent.type in ['declaration', 'parameter_declaration', 'init_declarator']:
                return True
            parent = parent.parent
        return False
    
    def _is_in_macro_context(self, node: Node) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨å®ä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­"""
        # æ£€æŸ¥æ˜¯å¦åœ¨é¢„å¤„ç†æŒ‡ä»¤ä¸­
        parent = node.parent
        while parent:
            if parent.type in ['preproc_call', 'preproc_defined', 'preproc_ifdef', 'preproc_ifndef']:
                return True
            parent = parent.parent
        return False
    
    def _is_likely_macro(self, name: str) -> bool:
        """åŸºäºå‘½åæ¨¡å¼åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å®"""
        if not name:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ³¨å†Œè¡¨ä¸­è¢«æ ‡è®°ä¸ºå®
        if name in self.symbol_registry:
            for symbol in self.symbol_registry[name]:
                if symbol.symbol_type == SymbolType.MACRO:
                    return True
        
        # å¯å‘å¼è§„åˆ™ï¼š
        # 1. å…¨å¤§å†™å­—æ¯åŠ ä¸‹åˆ’çº¿
        if name.isupper() and '_' in name:
            return True
        
        # 2. ä»¥å¸¸è§å®å‰ç¼€å¼€å¤´
        macro_prefixes = ['BINN_', 'API', 'MAX_', 'MIN_', '__', '_']
        for prefix in macro_prefixes:
            if name.startswith(prefix):
                return True
        
        return False
    
    def _extract_dependencies_by_pattern(self, text: str, source_symbol: Symbol) -> List[Dependency]:
        """åŸºäºæ¨¡å¼åŒ¹é…æå–ä¾èµ–å…³ç³»ï¼ˆå›é€€æ–¹æ³•ï¼‰"""
        dependencies = []
        
        # ç®€å•çš„æ ‡è¯†ç¬¦åŒ¹é…
        identifier_pattern = r'\b([a-zA-Z_][a-zA-Z0-9_]*)\b'
        matches = re.finditer(identifier_pattern, text)
        
        for match in matches:
            identifier = match.group(1)
            if self.is_valid_symbol_reference(identifier):
                # åŸºäºåŒ¹é…ä½ç½®ä¼°ç®—å‘ç”Ÿè¡Œå·ï¼ˆå±€éƒ¨è¡Œåç§» + å®šä¹‰èµ·å§‹è¡Œï¼‰
                pos = match.start()
                local_row = text.count('\n', 0, pos)
                start_line = source_symbol.start_line + local_row
                end_line = start_line
                dependencies.extend(self._create_dependencies_for_name(
                    identifier, source_symbol, DependencyType.VARIABLE_USE, None, (start_line, end_line)
                ))
        
        return dependencies
    
    def _create_dependencies_for_name(self, name: str, source_symbol: Symbol, 
                                     dep_type: DependencyType, node: Node = None,
                                     lines: Optional[Tuple[int, int]] = None) -> List[Dependency]:
        """ä¸ºç»™å®šåç§°åˆ›å»ºä¾èµ–å…³ç³»ï¼Œå¹¶è®¡ç®—å‘ç”Ÿä½ç½®è¡Œå·ã€‚"""
        dependencies = []
        start_line = 0
        end_line = 0

        if lines is not None:
            start_line, end_line = lines
        elif node is not None:
            try:
                # tree-sitter è¡Œå·ä¸º 0-basedï¼Œç›¸å¯¹ç‰‡æ®µå¼€å¤´ï¼›ç¬¦å·å®šä¹‰çš„ start_line è§†ä¸º 1-based
                sp = getattr(node, 'start_point', None)
                ep = getattr(node, 'end_point', None)
                if sp is not None and ep is not None:
                    srow = sp[0] if isinstance(sp, (tuple, list)) else getattr(sp, 'row', 0)
                    erow = ep[0] if isinstance(ep, (tuple, list)) else getattr(ep, 'row', 0)
                    start_line = source_symbol.start_line + int(srow)
                    end_line = source_symbol.start_line + int(erow)
            except Exception:
                pass
        
        if name in self.symbol_registry:
            # æ‰¾åˆ°æœ€åˆé€‚çš„ç›®æ ‡ç¬¦å·ï¼Œè€Œä¸æ˜¯æ‰€æœ‰åŒåç¬¦å·
            target_symbol = self._find_best_target_symbol(name, source_symbol, dep_type)
            if target_symbol and target_symbol != source_symbol:
                dependency = Dependency(
                    source_symbol=source_symbol,
                    target_symbol=target_symbol,
                    dependency_type=dep_type,
                    start_line=start_line,
                    end_line=end_line,
                )
                dependencies.append(dependency)
        
        return dependencies
    
    def _find_best_target_symbol(self, name: str, source_symbol: Symbol, dep_type: DependencyType) -> Optional[Symbol]:
        """æ‰¾åˆ°æœ€åˆé€‚çš„ç›®æ ‡ç¬¦å·ï¼Œè€ƒè™‘ä½œç”¨åŸŸå’Œå¯è§æ€§"""
        if name not in self.symbol_registry:
            return None
        
        candidates = self.symbol_registry[name]
        if not candidates:
            return None
        
        # è¿‡æ»¤æ ‡å‡†åº“ç¬¦å·å’Œå¸¸è§å®
        if self._is_standard_library_symbol(name):
            return None
        
        # 1. ä¼˜å…ˆé€‰æ‹©åŒæ–‡ä»¶å†…çš„ç¬¦å·
        same_file_candidates = [s for s in candidates if s.file_path == source_symbol.file_path]
        if same_file_candidates:
            return same_file_candidates[0]
        
        # 2. å¯¹äºå¤´æ–‡ä»¶å’Œå®ç°æ–‡ä»¶çš„å…³ç³»ï¼Œä¼˜å…ˆé€‰æ‹©å¤´æ–‡ä»¶ä¸­çš„ç¬¦å·
        if source_symbol.file_path.endswith('.c'):
            header_path = source_symbol.file_path.replace('.c', '.h')
            header_candidates = [s for s in candidates if s.file_path == header_path]
            if header_candidates:
                return header_candidates[0]
        
        # 3. è¿‡æ»¤æ‰æµ‹è¯•æ–‡ä»¶ä¸­çš„ç¬¦å·ï¼ˆé™¤éæºç¬¦å·ä¹Ÿåœ¨æµ‹è¯•æ–‡ä»¶ä¸­ï¼‰
        if not self._is_test_file(source_symbol.file_path):
            non_test_candidates = [s for s in candidates if not self._is_test_file(s.file_path)]
            if non_test_candidates:
                candidates = non_test_candidates
        
        # 4. ä¼˜å…ˆé€‰æ‹©ä¸ä¾èµ–ç±»å‹åŒ¹é…çš„ç¬¦å·ç±»å‹
        type_matched_candidates = self._filter_by_dependency_type(candidates, dep_type)
        if type_matched_candidates:
            candidates = type_matched_candidates
        
        # 5. å¦‚æœè¿˜æœ‰å¤šä¸ªå€™é€‰ï¼Œé€‰æ‹©è·¯å¾„æœ€ç›¸ä¼¼çš„
        if len(candidates) > 1:
            return self._find_most_similar_path(candidates, source_symbol.file_path)
        
        return candidates[0] if candidates else None
    
    def _is_standard_library_symbol(self, name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡å‡†åº“ç¬¦å·"""
        standard_symbols = {
            # æ ‡å‡†æ–­è¨€å®
            'assert',
            # æ ‡å‡†I/Oå‡½æ•°
            'printf', 'scanf', 'fprintf', 'sprintf', 'snprintf',
            'fopen', 'fclose', 'fread', 'fwrite', 'fgets', 'fputs',
            # å†…å­˜ç®¡ç†
            'malloc', 'calloc', 'realloc', 'free',
            # å­—ç¬¦ä¸²å‡½æ•°
            'strlen', 'strcpy', 'strncpy', 'strcmp', 'strncmp', 'strcat', 'strncat',
            # æ•°å­¦å‡½æ•°
            'abs', 'fabs', 'sqrt', 'pow', 'sin', 'cos', 'tan',
            # å…¶ä»–å¸¸è§æ ‡å‡†åº“ç¬¦å·
            'exit', 'abort', 'atexit', 'getenv', 'system',
        }
        return name in standard_symbols
    
    def _is_test_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæµ‹è¯•æ–‡ä»¶"""
        path_lower = file_path.lower()
        return ('test' in path_lower or 
                '/test/' in path_lower or 
                path_lower.startswith('test') or
                path_lower.endswith('_test.c') or
                path_lower.endswith('_test.h'))
    
    def _filter_by_dependency_type(self, candidates: List[Symbol], dep_type: DependencyType) -> List[Symbol]:
        """æ ¹æ®ä¾èµ–ç±»å‹è¿‡æ»¤å€™é€‰ç¬¦å·"""
        if dep_type == DependencyType.FUNCTION_CALL:
            return [s for s in candidates if s.symbol_type == SymbolType.FUNCTION]
        elif dep_type == DependencyType.TYPE_REFERENCE:
            return [s for s in candidates if s.symbol_type in [SymbolType.STRUCT, SymbolType.TYPEDEF]]
        elif dep_type == DependencyType.MACRO_USE:
            return [s for s in candidates if s.symbol_type == SymbolType.MACRO]
        elif dep_type == DependencyType.ENUM_USE:
            return [s for s in candidates if s.symbol_type == SymbolType.ENUM]
        elif dep_type == DependencyType.VARIABLE_USE:
            return [s for s in candidates if s.symbol_type == SymbolType.VARIABLE]
        else:
            return candidates
    
    def _find_most_similar_path(self, candidates: List[Symbol], source_path: str) -> Symbol:
        """æ‰¾åˆ°è·¯å¾„æœ€ç›¸ä¼¼çš„ç¬¦å·"""
        source_parts = Path(source_path).parts
        
        def path_similarity(candidate_path: str) -> int:
            candidate_parts = Path(candidate_path).parts
            common_parts = 0
            min_len = min(len(source_parts), len(candidate_parts))
            for i in range(min_len):
                if source_parts[-(i+1)] == candidate_parts[-(i+1)]:
                    common_parts += 1
                else:
                    break
            return common_parts
        
        return max(candidates, key=lambda s: path_similarity(s.file_path))
    
    def _build_file_dependencies(self) -> Dict:
        """æ„å»ºæ–‡ä»¶çº§åˆ«çš„ä¾èµ–å…³ç³»"""
        from collections import defaultdict
        
        # æ–‡ä»¶åˆ°æ–‡ä»¶çš„ä¾èµ–æ˜ å°„
        file_to_files = defaultdict(set)
        file_to_symbols = defaultdict(set)
        
        # æ”¶é›†æ¯ä¸ªæ–‡ä»¶åŒ…å«çš„ç¬¦å·
        for symbol in self.dependency_graph.symbols.values():
            file_to_symbols[symbol.file_path].add(symbol.name)
        
        # æ ¹æ®ç¬¦å·ä¾èµ–æ„å»ºæ–‡ä»¶ä¾èµ–
        for dep in self.dependency_graph.dependencies:
            src_file = dep.source_symbol.file_path
            tgt_file = dep.target_symbol.file_path
            
            # åªè®°å½•è·¨æ–‡ä»¶ä¾èµ–
            if src_file != tgt_file:
                file_to_files[src_file].add(tgt_file)
        
        # æ„å»ºå¯¼å‡ºæ ¼å¼
        file_dependencies = {
            'files': {},
            'dependencies': []
        }
        
        # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
        all_files = set(file_to_symbols.keys())
        for dep_files in file_to_files.values():
            all_files.update(dep_files)
        
        for file_path in sorted(all_files):
            symbols_in_file = list(file_to_symbols.get(file_path, set()))
            file_dependencies['files'][file_path] = {
                'path': file_path,
                'symbol_count': len(symbols_in_file),
                'symbols': sorted(symbols_in_file)
            }
        
        # æ·»åŠ æ–‡ä»¶é—´ä¾èµ–å…³ç³»
        for src_file, tgt_files in file_to_files.items():
            for tgt_file in tgt_files:
                # ç»Ÿè®¡è¿™ä¸¤ä¸ªæ–‡ä»¶ä¹‹é—´çš„ç¬¦å·ä¾èµ–æ•°é‡å’Œç±»å‹
                cross_deps = [dep for dep in self.dependency_graph.dependencies 
                             if dep.source_symbol.file_path == src_file and 
                                dep.target_symbol.file_path == tgt_file]
                
                if cross_deps:
                    # æŒ‰ä¾èµ–ç±»å‹åˆ†ç»„
                    dep_types = defaultdict(int)
                    for dep in cross_deps:
                        dep_types[dep.dependency_type.value] += 1
                    
                    file_dependencies['dependencies'].append({
                        'source_file': src_file,
                        'target_file': tgt_file,
                        'dependency_count': len(cross_deps),
                        'dependency_types': dict(dep_types)
                    })
        
        return file_dependencies
    
    def analyze_all_dependencies(self):
        """åˆ†ææ‰€æœ‰ç¬¦å·çš„ä¾èµ–å…³ç³»"""
        print("å¼€å§‹åˆ†æç¬¦å·ä¾èµ–å…³ç³»...")
        
        total_symbols = len(self.dependency_graph.symbols)
        analyzed_count = 0
        error_count = 0
        total_found_deps = 0
        total_added_deps = 0
        
        for symbol in self.dependency_graph.symbols.values():
            try:
                # æå–è¯¥ç¬¦å·å®šä¹‰ä¸­çš„ä¾èµ–
                if symbol.definition:
                    dependencies = self.extract_dependencies_from_text(symbol.definition, symbol)
                    total_found_deps += len(dependencies)
                    
                    for dep in dependencies:
                        if self.dependency_graph.add_dependency(dep):
                            total_added_deps += 1
                
                analyzed_count += 1
                
                # æ˜¾ç¤ºè¿›åº¦
                if analyzed_count % 50 == 0 or analyzed_count == total_symbols:
                    progress = (analyzed_count / total_symbols) * 100
                    duplicate_rate = ((total_found_deps - total_added_deps) / max(total_found_deps, 1)) * 100
                    print(f"è¿›åº¦: {analyzed_count}/{total_symbols} ({progress:.1f}%) - "
                          f"å‘ç°: {total_found_deps}, æ·»åŠ : {total_added_deps}, é‡å¤ç‡: {duplicate_rate:.1f}% - é”™è¯¯: {error_count}")
                    
            except Exception as e:
                error_count += 1
                print(f"åˆ†æç¬¦å· {symbol.name} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"ä¾èµ–å…³ç³»åˆ†æå®Œæˆï¼š")
        print(f"  âœ… æˆåŠŸåˆ†æ: {analyzed_count - error_count}/{total_symbols} ä¸ªç¬¦å·")
        print(f"  âŒ åˆ†æé”™è¯¯: {error_count} ä¸ªç¬¦å·")
        print(f"  ğŸ“Š å‘ç°ä¾èµ–: {total_found_deps} ä¸ª")
        print(f"  ğŸ“Š å®é™…æ·»åŠ : {total_added_deps} ä¸ª")
        print(f"  ğŸ”„ å»é‡æ•°é‡: {total_found_deps - total_added_deps} ä¸ª")
        print(f"  ğŸ“ˆ å»é‡ç‡: {((total_found_deps - total_added_deps) / max(total_found_deps, 1)) * 100:.1f}%")
    
    def export_dependencies_to_json(self, output_path: str):
        """å¯¼å‡ºä¾èµ–å…³ç³»åˆ°JSONæ–‡ä»¶"""
        try:
            # æ„å»ºæ–‡ä»¶çº§åˆ«ä¾èµ–å…³ç³»
            file_dependencies = self._build_file_dependencies()
            
            export_data = {
                'metadata': {
                    'total_symbols': len(self.dependency_graph.symbols),
                    'total_dependencies': len(self.dependency_graph.dependencies),
                    'total_files': len(file_dependencies),
                    'statistics': self.get_dependency_statistics()
                },
                'symbols': {},
                'dependencies': [],
                'file_dependencies': file_dependencies
            }
            
            # å¯¼å‡ºç¬¦å·ä¿¡æ¯
            for symbol in self.dependency_graph.symbols.values():
                key = f"{symbol.name}:{symbol.symbol_type.value}:{symbol.file_path}"
                export_data['symbols'][key] = {
                    'name': symbol.name,
                    'type': symbol.symbol_type.value,
                    'file_path': symbol.file_path,
                    'start_line': symbol.start_line,
                    'end_line': symbol.end_line
                }
            
            # å¯¼å‡ºä¾èµ–å…³ç³»
            for dep in self.dependency_graph.dependencies:
                export_data['dependencies'].append({
                    'source': {
                        'name': dep.source_symbol.name,
                        'type': dep.source_symbol.symbol_type.value,
                        'file': dep.source_symbol.file_path
                    },
                    'target': {
                        'name': dep.target_symbol.name,
                        'type': dep.target_symbol.symbol_type.value,
                        'file': dep.target_symbol.file_path
                    },
                    'dependency_type': dep.dependency_type.value,
                    'occurrence': {
                        'start_line': dep.start_line,
                        'end_line': dep.end_line,
                    }
                })
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… ä¾èµ–å…³ç³»å·²å¯¼å‡ºåˆ°: {output_path}")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
    
    def generate_dependency_report(self) -> str:
        """ç”Ÿæˆä¾èµ–å…³ç³»æŠ¥å‘Š"""
        stats = self.get_dependency_statistics()
        
        report = []
        report.append("=" * 60)
        report.append("           Cé¡¹ç›®ç¬¦å·ä¾èµ–å…³ç³»åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report.append("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        report.append(f"  ç¬¦å·æ€»æ•°: {stats['total_symbols']}")
        report.append(f"  ä¾èµ–æ€»æ•°: {stats['total_dependencies']}")
        report.append("")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ç¬¦å·
        report.append("ğŸ“‹ ç¬¦å·åˆ†å¸ƒ:")
        for symbol_type, count in stats['symbols_by_type'].items():
            report.append(f"  {symbol_type}: {count}")
        report.append("")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ä¾èµ–
        report.append("ğŸ”— ä¾èµ–åˆ†å¸ƒ:")
        for dep_type, count in stats['dependencies_by_type'].items():
            report.append(f"  {dep_type}: {count}")
        report.append("")
        
        # Top 10 æœ€å¤šä¾èµ–çš„ç¬¦å·
        symbol_dep_count = {}
        for dep in self.dependency_graph.dependencies:
            source_name = dep.source_symbol.name
            symbol_dep_count[source_name] = symbol_dep_count.get(source_name, 0) + 1
        
        top_symbols = sorted(symbol_dep_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        report.append("ğŸ” ä¾èµ–æœ€å¤šçš„ç¬¦å· (Top 10):")
        for i, (symbol_name, dep_count) in enumerate(top_symbols, 1):
            report.append(f"  {i:2d}. {symbol_name}: {dep_count} ä¸ªä¾èµ–")
        report.append("")
        
        # Top 10 è¢«ä¾èµ–æœ€å¤šçš„ç¬¦å·
        target_dep_count = {}
        for dep in self.dependency_graph.dependencies:
            target_name = dep.target_symbol.name
            target_dep_count[target_name] = target_dep_count.get(target_name, 0) + 1
        
        top_targets = sorted(target_dep_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        report.append("ğŸ¯ è¢«ä¾èµ–æœ€å¤šçš„ç¬¦å· (Top 10):")
        for i, (symbol_name, dep_count) in enumerate(top_targets, 1):
            report.append(f"  {i:2d}. {symbol_name}: è¢« {dep_count} ä¸ªç¬¦å·ä¾èµ–")
        
        report.append("")
        report.append("=" * 60)
        
        return "\n".join(report)
    
    def get_dependency_statistics(self) -> Dict:
        """è·å–ä¾èµ–å…³ç³»ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_symbols': len(self.dependency_graph.symbols),
            'total_dependencies': len(self.dependency_graph.dependencies),
            'symbols_by_type': {},
            'dependencies_by_type': {}
        }
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ç¬¦å·
        for symbol in self.dependency_graph.symbols.values():
            symbol_type = symbol.symbol_type.value
            stats['symbols_by_type'][symbol_type] = stats['symbols_by_type'].get(symbol_type, 0) + 1
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ä¾èµ–
        for dep in self.dependency_graph.dependencies:
            dep_type = dep.dependency_type.value
            stats['dependencies_by_type'][dep_type] = stats['dependencies_by_type'].get(dep_type, 0) + 1
        
        return stats

def main() -> int:
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´åŠŸèƒ½"""
    import argparse
    import time

    parser = argparse.ArgumentParser(description="ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨")
    parser.add_argument(
        "--analysis",
        default=str(_DEFAULT_ANALYSIS_PATH),
        help="C é¡¹ç›®åˆ†æç»“æœ JSON è·¯å¾„ï¼ˆé»˜è®¤è¯»å–é…ç½®çš„è¾“å‡ºç›®å½•ï¼‰",
    )
    parser.add_argument(
        "--output",
        default=str(_DEFAULT_DEPENDENCIES_PATH),
        help="ç¬¦å·ä¾èµ–ç»“æœè¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤å†™å…¥é…ç½®çš„è¾“å‡ºç›®å½•ï¼‰",
    )

    args = parser.parse_args()

    analysis_path = Path(args.analysis)
    if not analysis_path.is_absolute():
        analysis_path = (_DEFAULT_OUTPUT_DIR / analysis_path).resolve()

    if not analysis_path.exists():
        print(f"âŒ åˆ†æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {analysis_path}")
        return 1

    output_path = Path(args.output)
    if not output_path.is_absolute():
        output_path = (_DEFAULT_OUTPUT_DIR / output_path).resolve()
    output_path.parent.mkdir(parents=True, exist_ok=True)

    start_time = time.time()

    analyzer = SymbolDependencyAnalyzer(str(analysis_path))

    print("=== ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨ ===")
    print("ç¬¬äºŒé˜¶æ®µï¼šå®Œæ•´çš„ä¾èµ–å…³ç³»åˆ†æ")
    print()

    # æ„å»ºç¬¦å·æ³¨å†Œè¡¨
    print("1ï¸âƒ£ æ„å»ºç¬¦å·æ³¨å†Œè¡¨...")
    analyzer.build_symbol_registry()

    # åˆ†æä¾èµ–å…³ç³»
    print("\n2ï¸âƒ£ åˆ†æç¬¦å·ä¾èµ–å…³ç³»...")
    analyzer.analyze_all_dependencies()

    # ç”ŸæˆæŠ¥å‘Š
    print("\n3ï¸âƒ£ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report = analyzer.generate_dependency_report()
    print(report)

    # å¯¼å‡ºç»“æœ
    print("\n4ï¸âƒ£ å¯¼å‡ºåˆ†æç»“æœ...")
    analyzer.export_dependencies_to_json(str(output_path))

    # æ€§èƒ½ç»Ÿè®¡
    end_time = time.time()
    print(f"\nâ±ï¸ æ€»ç”¨æ—¶: {end_time - start_time:.2f} ç§’")
    print(f"ğŸ“ ç»“æœå†™å…¥: {output_path}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
