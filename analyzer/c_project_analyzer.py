#!/usr/bin/env python3
"""
æ¼”ç¤ºTree-sitterè§£ææ•´ä¸ªCå·¥ç¨‹çš„æ‰€æœ‰.cå’Œ.hæ–‡ä»¶
"""

import os
import glob
import tree_sitter_c as ts_c
from tree_sitter import Language, Parser
from pathlib import Path
import json
import sys

try:  # å…¼å®¹è„šæœ¬ç›´æ¥æ‰§è¡Œä¸æ¨¡å—å¯¼å…¥
    from config import get_project_root, to_relative_path
except ImportError:  # pragma: no cover
    from .config import get_project_root, to_relative_path

class CProjectAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–Cå·¥ç¨‹åˆ†æå™¨"""
        self.C_LANGUAGE = Language(ts_c.language())
        self.parser = Parser(self.C_LANGUAGE)
        self.analysis_results = {}
        self.project_root = get_project_root()
    
    def find_c_files(self, project_path):
        """æŸ¥æ‰¾é¡¹ç›®ä¸­æ‰€æœ‰çš„Cå’ŒHæ–‡ä»¶"""
        c_files = []
        h_files = []
        project_str = str(project_path)
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰.cæ–‡ä»¶
        c_pattern = os.path.join(project_str, "**", "*.c")
        c_files.extend(glob.glob(c_pattern, recursive=True))
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰.hæ–‡ä»¶
        h_pattern = os.path.join(project_str, "**", "*.h")
        h_files.extend(glob.glob(h_pattern, recursive=True))
        
        return c_files, h_files
    
    def parse_single_file(self, file_path):
        """è§£æå•ä¸ªC/Hæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # è§£ææ–‡ä»¶
            tree = self.parser.parse(bytes(content, "utf8"))
            root_node = tree.root_node
            
            # æå–è¯­æ³•å…ƒç´ 
            functions = self.extract_functions(root_node, content, root_node)
            structs = self.extract_structs(root_node, content, root_node)
            includes = self.extract_includes(root_node, content)
            variables = self.extract_global_variables(root_node, content, root_node)
            typedefs = self.extract_typedefs(root_node, content, root_node)
            macros = self.extract_macros(root_node, content, root_node)
            enums = self.extract_enums(root_node, content, root_node)
            
            # åˆ›å»ºåˆå§‹æ•°æ®
            raw_data = {
                'functions': functions,
                'structs': structs,
                'includes': includes,
                'variables': variables,
                'typedefs': typedefs,
                'macros': macros,
                'enums': enums
            }
            
            # åº”ç”¨é€šç”¨å»é‡é€»è¾‘
            deduplicated_data = self.deduplicate_elements(raw_data)
            
            rel_path = to_relative_path(file_path)

            return {
                'file_path': rel_path,
                'parse_success': True,
                'functions': deduplicated_data['functions'],
                'structs': deduplicated_data['structs'],
                'includes': includes,  # includesä¸éœ€è¦å»é‡
                'variables': deduplicated_data['variables'],
                'typedefs': deduplicated_data['typedefs'],
                'macros': deduplicated_data['macros'],
                'enums': deduplicated_data['enums'],
                'total_nodes': self.count_nodes(root_node),
                'file_size': len(content)
            }
            
        except Exception as e:
            return {
                'file_path': to_relative_path(file_path),
                'parse_success': False,
                'error': str(e)
            }
    
    def deduplicate_elements(self, file_data):
        """
        é€šç”¨å»é‡æ–¹æ³•ï¼šåŸºäºstart_byteå’Œend_byteçš„åŒ…å«å…³ç³»å»é‡
        å¦‚æœå…ƒç´ Aå®Œå…¨åŒ…å«å…ƒç´ Bï¼Œåˆ™ç§»é™¤è¢«åŒ…å«çš„å…ƒç´ B
        """
        all_elements = []
        
        # æ”¶é›†æ‰€æœ‰å…ƒç´ ï¼Œæ·»åŠ ç±»å‹æ ‡è®°
        for element_type in ['functions', 'structs', 'typedefs', 'variables', 'macros', 'enums']:
            if element_type in file_data:
                for element in file_data[element_type]:
                    if 'start_byte' in element and 'end_byte' in element:
                        element_with_type = element.copy()
                        element_with_type['_element_type'] = element_type
                        all_elements.append(element_with_type)
        
        # æŒ‰start_byteæ’åº
        all_elements.sort(key=lambda x: x['start_byte'])
        
        # å»é‡ï¼šç§»é™¤è¢«å®Œå…¨åŒ…å«çš„å…ƒç´ 
        filtered_elements = []
        for i, current in enumerate(all_elements):
            is_contained = False
            
            # æ£€æŸ¥æ˜¯å¦è¢«å…¶ä»–å…ƒç´ å®Œå…¨åŒ…å«
            for j, other in enumerate(all_elements):
                if i != j:
                    # otherå®Œå…¨åŒ…å«current
                    if (other['start_byte'] <= current['start_byte'] and 
                        other['end_byte'] >= current['end_byte'] and
                        (other['start_byte'] != current['start_byte'] or 
                         other['end_byte'] != current['end_byte'])):
                        is_contained = True
                        break
            
            if not is_contained:
                filtered_elements.append(current)
        
        # é‡æ–°åˆ†ç»„åˆ°å„ä¸ªç±»å‹
        result = {}
        for element_type in ['functions', 'structs', 'typedefs', 'variables', 'macros', 'enums']:
            result[element_type] = []
            for element in filtered_elements:
                if element.get('_element_type') == element_type:
                    # ç§»é™¤ä¸´æ—¶çš„ç±»å‹æ ‡è®°
                    clean_element = {k: v for k, v in element.items() if k != '_element_type'}
                    result[element_type].append(clean_element)
        
        return result
    
    def extract_functions(self, node, content, root_node):
        """æå–å‡½æ•°å®šä¹‰å’Œå£°æ˜"""
        functions = []
        
        def traverse(node):
            if node.type == 'function_definition':
                func_info = self.parse_function(node, content, root_node)
                if func_info:
                    functions.append(func_info)
            elif node.type == 'declaration':
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°å£°æ˜ï¼ˆåŒ…æ‹¬æŒ‡é’ˆè¿”å›ç±»å‹ï¼‰
                has_function_declarator = False
                for child in node.children:
                    if child.type == 'function_declarator':
                        has_function_declarator = True
                        break
                    elif child.type == 'pointer_declarator':
                        # æ£€æŸ¥æŒ‡é’ˆå£°æ˜ä¸­æ˜¯å¦åŒ…å«å‡½æ•°å£°æ˜
                        def check_pointer_declarator(ptr_node):
                            for subchild in ptr_node.children:
                                if subchild.type == 'function_declarator':
                                    return True
                                elif subchild.type == 'pointer_declarator':
                                    if check_pointer_declarator(subchild):
                                        return True
                            return False
                        if check_pointer_declarator(child):
                            has_function_declarator = True
                            break
                
                if has_function_declarator:
                    func_info = self.parse_function_declaration(node, content, root_node)
                    if func_info:
                        functions.append(func_info)
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        return functions
    
    def correct_byte_offset(self, node, content, original_func_name=None):
        """ä¿®æ­£Tree-sitterçš„å­—èŠ‚åç§»é”™è¯¯"""
        try:
            # è·å–Tree-sitteræŠ¥å‘Šçš„ä½ç½®
            ts_start = node.start_byte
            ts_end = node.end_byte
            
            # å…ˆå°è¯•ä»ä¿®æ­£åçš„å†…å®¹ä¸­æå–å‡½æ•°å
            corrected_func_name = self.extract_function_name_from_content(ts_start, ts_end, content)
            
            if corrected_func_name:
                # ä½¿ç”¨æå–åˆ°çš„å‡½æ•°åæ¥æŸ¥æ‰¾æ­£ç¡®çš„ä½ç½®
                search_func_name = corrected_func_name
            elif original_func_name:
                # ä½¿ç”¨åŸå§‹å‡½æ•°å
                search_func_name = original_func_name
            else:
                # éƒ½æ²¡æœ‰ï¼Œè¿”å›åŸå§‹ä½ç½®
                return ts_start, ts_end
            
            # åœ¨åŸå§‹å†…å®¹ä¸­æœç´¢æ­£ç¡®çš„å‡½æ•°ä½ç½®
            func_name_positions = []
            start_pos = 0
            while True:
                pos = content.find(search_func_name, start_pos)
                if pos == -1:
                    break
                func_name_positions.append(pos)
                start_pos = pos + 1
            
            if not func_name_positions:
                return ts_start, ts_end
            
            # æ‰¾åˆ°æœ€æ¥è¿‘Tree-sitteræŠ¥å‘Šä½ç½®çš„å‡½æ•°å
            best_func_pos = min(func_name_positions, key=lambda x: abs(x - ts_start))
            
            # ä»å‡½æ•°åä½ç½®å‘å‰æœç´¢ï¼Œæ‰¾åˆ°å‡½æ•°å®šä¹‰çš„çœŸæ­£å¼€å§‹
            lines_before = content[:best_func_pos].split('\n')
            current_line_start = len('\n'.join(lines_before[:-1])) + (1 if len(lines_before) > 1 else 0)
            current_line = lines_before[-1] if lines_before else ""
            
            # æ£€æŸ¥å‡½æ•°åå‰é¢æ˜¯å¦æœ‰å…¶ä»–tokensï¼ˆè¿”å›ç±»å‹ç­‰ï¼‰
            prefix = current_line[:best_func_pos - current_line_start]
            tokens = prefix.strip().split()
            
            if tokens:
                # å½“å‰è¡Œæœ‰è¿”å›ç±»å‹æˆ–ä¿®é¥°ç¬¦ï¼Œä»è¡Œå¼€å§‹ç®—
                corrected_start = current_line_start
            else:
                # å½“å‰è¡Œåªæœ‰å‡½æ•°åï¼Œæ£€æŸ¥ä¸Šä¸€è¡Œæ˜¯å¦æœ‰è¿”å›ç±»å‹
                if len(lines_before) >= 2:
                    prev_line = lines_before[-2].strip()
                    if prev_line and not prev_line.endswith(';') and not prev_line.startswith('//') and not prev_line.startswith('/*'):
                        # ä¸Šä¸€è¡Œå¯èƒ½æ˜¯è¿”å›ç±»å‹ï¼Œä»ä¸Šä¸€è¡Œå¼€å§‹
                        prev_line_start = len('\n'.join(lines_before[:-2])) + (1 if len(lines_before) > 2 else 0)
                        corrected_start = prev_line_start
                    else:
                        corrected_start = current_line_start
                else:
                    corrected_start = current_line_start
            
            # å¯¹äºå‡½æ•°å®šä¹‰ï¼Œç»“æŸä½ç½®é€šå¸¸æ˜¯æ­£ç¡®çš„
            corrected_end = ts_end
            
            return corrected_start, corrected_end
            
        except Exception:
            # å‡ºé”™æ—¶ä½¿ç”¨åŸå§‹ä½ç½®
            return node.start_byte, node.end_byte
    
    def extract_function_name_from_content(self, start_byte, end_byte, content):
        """ä»æŒ‡å®šå­—èŠ‚èŒƒå›´ä¸­æå–å‡½æ•°å"""
        try:
            section_content = content[start_byte:end_byte]
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å‡½æ•°å
            import re
            
            # åŒ¹é…å‡½æ•°å®šä¹‰çš„æ¨¡å¼
            patterns = [
                r'(?:static\s+)?(?:\w+\s+)*(\w+)\s*\([^)]*\)\s*\{',  # å®Œæ•´æ¨¡å¼ï¼š[static] è¿”å›ç±»å‹ å‡½æ•°å(å‚æ•°){
                r'\b(\w+)\s*\([^)]*\)\s*\{',  # ç®€å•æ¨¡å¼ï¼šå‡½æ•°å(å‚æ•°){
            ]
            
            for pattern in patterns:
                match = re.search(pattern, section_content)
                if match:
                    return match.group(1)
            
            return None
            
        except Exception:
            return None

    def parse_function(self, node, content, root_node):
        """è§£æå‡½æ•°å®šä¹‰"""
        try:
            # é¦–å…ˆä¿®æ­£å­—èŠ‚åç§»
            corrected_start, corrected_end = self.correct_byte_offset(node, content)
            
            # ä»ä¿®æ­£åçš„å†…å®¹ä¸­æå–å‡½æ•°å
            func_name = self.extract_function_name_from_content(corrected_start, corrected_end, content)
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°å‡½æ•°åï¼Œå°è¯•ä½¿ç”¨Tree-sitterçš„ç»“æœä½œä¸ºå¤‡é€‰
            if not func_name:
                def find_function_info(child_node):
                    nonlocal func_name
                    if child_node.type == 'function_declarator':
                        for subchild in child_node.children:
                            if subchild.type == 'identifier':
                                func_name = content[subchild.start_byte:subchild.end_byte]
                                break
                    elif child_node.type == 'pointer_declarator':
                        for subchild in child_node.children:
                            find_function_info(subchild)
                
                for child in node.children:
                    if child.type == 'function_declarator':
                        find_function_info(child)
                    elif child.type == 'pointer_declarator':
                        find_function_info(child)
            
            if not func_name:
                return None
            
            # æå–å…¶ä»–ä¿¡æ¯
            return_type = None
            parameters = []
            
            def find_function_info(child_node):
                nonlocal parameters
                if child_node.type == 'function_declarator':
                    for subchild in child_node.children:
                        if subchild.type == 'parameter_list':
                            parameters = self.parse_parameters(subchild, content)
                elif child_node.type == 'pointer_declarator':
                    for subchild in child_node.children:
                        find_function_info(subchild)
            
            for child in node.children:
                if child.type == 'primitive_type' or child.type == 'type_identifier':
                    return_type = content[child.start_byte:child.end_byte].strip()
                elif child.type == 'function_declarator':
                    find_function_info(child)
                elif child.type == 'pointer_declarator':
                    find_function_info(child)
            
            # æå–å®Œæ•´çš„å‡½æ•°å®šä¹‰å†…å®¹ï¼ˆä½¿ç”¨ä¿®æ­£åçš„ä½ç½®ï¼‰
            full_definition = content[corrected_start:corrected_end]
            
            # æå–å‡½æ•°ç­¾åï¼ˆä¸åŒ…æ‹¬å‡½æ•°ä½“ï¼‰
            signature = self.extract_function_signature_corrected(corrected_start, corrected_end, content)
            
            # æå–å‰ç½®æ³¨é‡Š
            comment = self.extract_preceding_comment(node, root_node, content)
            
            result = {
                'name': func_name,
                'type': 'definition',
                # 'return_type': return_type if return_type else '',
                # 'parameters': parameters,
                'start_line': node.start_point[0] + 1,
                'end_line': node.end_point[0] + 1,
                'start_byte': corrected_start,
                'end_byte': corrected_end,
                'signature': signature,
                'full_definition': full_definition,
                'comment': comment if comment else ''
            }
                
            return result
        except:
            pass
        return None
    
    def extract_function_signature_corrected(self, start_byte, end_byte, content):
        """ä½¿ç”¨ä¿®æ­£åçš„å­—èŠ‚ä½ç½®æå–å‡½æ•°ç­¾å"""
        try:
            full_text = content[start_byte:end_byte]
            
            # æŸ¥æ‰¾å‡½æ•°ä½“çš„å¼€å§‹ä½ç½®ï¼ˆç¬¬ä¸€ä¸ª { ï¼‰
            brace_pos = full_text.find('{')
            if brace_pos >= 0:
                # å‡½æ•°ç­¾åæ˜¯ä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªå¤§æ‹¬å·ä¹‹å‰
                signature = full_text[:brace_pos].strip()
                return signature
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¤§æ‹¬å·ï¼Œå¯èƒ½æ˜¯å£°æ˜ï¼Œè¿”å›æ•´ä¸ªå†…å®¹
            return full_text.strip()
        except:
            return content[start_byte:end_byte].strip()

    def parse_function_declaration(self, node, content, root_node):
        """è§£æå‡½æ•°å£°æ˜"""
        try:
            # é¦–å…ˆä¿®æ­£å­—èŠ‚åç§»
            corrected_start, corrected_end = self.correct_byte_offset(node, content)
            
            # ä»ä¿®æ­£åçš„å†…å®¹ä¸­æå–å‡½æ•°å
            func_name = self.extract_function_name_from_content(corrected_start, corrected_end, content)
            
            # å¦‚æœæ²¡æœ‰æå–åˆ°å‡½æ•°åï¼Œå°è¯•ä½¿ç”¨Tree-sitterçš„ç»“æœä½œä¸ºå¤‡é€‰
            if not func_name:
                def find_function_info(child_node):
                    nonlocal func_name
                    if child_node.type == 'function_declarator':
                        for subchild in child_node.children:
                            if subchild.type == 'identifier':
                                func_name = content[subchild.start_byte:subchild.end_byte]
                                break
                    elif child_node.type == 'pointer_declarator':
                        for subchild in child_node.children:
                            find_function_info(subchild)
                
                for child in node.children:
                    if child.type == 'function_declarator':
                        find_function_info(child)
                    elif child.type == 'pointer_declarator':
                        find_function_info(child)
            
            if not func_name:
                return None
            
            # æå–å…¶ä»–ä¿¡æ¯
            return_type = None
            parameters = []
            
            def find_function_info(child_node):
                nonlocal parameters
                if child_node.type == 'function_declarator':
                    for subchild in child_node.children:
                        if subchild.type == 'parameter_list':
                            parameters = self.parse_parameters(subchild, content)
                elif child_node.type == 'pointer_declarator':
                    for subchild in child_node.children:
                        find_function_info(subchild)
            
            for child in node.children:
                if child.type == 'primitive_type' or child.type == 'type_identifier':
                    return_type = content[child.start_byte:child.end_byte].strip()
                elif child.type == 'function_declarator':
                    find_function_info(child)
                elif child.type == 'pointer_declarator':
                    find_function_info(child)
            
            # æå–å®Œæ•´çš„å‡½æ•°å£°æ˜å†…å®¹ï¼ˆä½¿ç”¨ä¿®æ­£åçš„ä½ç½®ï¼‰
            full_declaration = content[corrected_start:corrected_end].strip()
            
            # æå–å‰ç½®æ³¨é‡Š
            comment = self.extract_preceding_comment(node, root_node, content)
            
            result = {
                'name': func_name,
                'type': 'declaration',
                # 'return_type': return_type if return_type else '',
                # 'parameters': parameters,
                'start_line': node.start_point[0] + 1,
                'end_line': node.end_point[0] + 1,
                'start_byte': corrected_start,
                'end_byte': corrected_end,
                'full_declaration': full_declaration,
                'comment': comment if comment else ''
            }
                
            return result
        except:
            pass
        return None
    
    def parse_parameters(self, param_node, content):
        """è§£æå‡½æ•°å‚æ•°"""
        parameters = []
        for child in param_node.children:
            if child.type == 'parameter_declaration':
                param_text = content[child.start_byte:child.end_byte].strip()
                if param_text and param_text != ',':
                    parameters.append(param_text)
        return parameters
    
    def extract_function_signature(self, node, content):
        """æå–å‡½æ•°ç­¾åï¼ˆä¸åŒ…æ‹¬å‡½æ•°ä½“ï¼‰"""
        try:
            # æŸ¥æ‰¾å‡½æ•°ä½“çš„å¼€å§‹ä½ç½®
            for child in node.children:
                if child.type == 'compound_statement':
                    # å‡½æ•°ç­¾åæ˜¯ä»å‡½æ•°å¼€å§‹åˆ°å‡½æ•°ä½“å¼€å§‹ä¹‹å‰
                    signature_end = child.start_byte
                    signature = content[node.start_byte:signature_end].strip()
                    return signature
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‡½æ•°ä½“ï¼Œè¿”å›æ•´ä¸ªèŠ‚ç‚¹å†…å®¹
            return content[node.start_byte:node.end_byte].strip()
        except:
            return content[node.start_byte:node.end_byte].strip()
    
    def extract_structs(self, node, content, root_node):
        """æå–ç»“æ„ä½“å®šä¹‰"""
        structs = []
        
        def traverse(node):
            if node.type == 'struct_specifier':
                struct_name = None
                for child in node.children:
                    if child.type == 'type_identifier':
                        struct_name = content[child.start_byte:child.end_byte]
                        break
                
                if struct_name:
                    # æå–å®Œæ•´çš„ç»“æ„ä½“å®šä¹‰
                    full_definition = content[node.start_byte:node.end_byte]
                    
                    # æå–ç»“æ„ä½“å­—æ®µ
                    fields = self.extract_struct_fields(node, content)
                    
                    # æå–å‰ç½®æ³¨é‡Š
                    comment = self.extract_preceding_comment(node, root_node, content)
                    
                    struct_info = {
                        'name': struct_name,
                        'start_line': node.start_point[0] + 1,
                        'end_line': node.end_point[0] + 1,
                        'start_byte': node.start_byte,
                        'end_byte': node.end_byte,
                        'full_definition': full_definition,
                        'fields': fields,
                        'comment': comment if comment else ''
                    }
                        
                    structs.append(struct_info)
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        return structs
    
    def extract_struct_fields(self, struct_node, content):
        """æå–ç»“æ„ä½“å­—æ®µ"""
        fields = []
        
        def traverse(node):
            if node.type == 'field_declaration':
                field_text = content[node.start_byte:node.end_byte].strip()
                if field_text:
                    fields.append({
                        'text': field_text,
                        'line': node.start_point[0] + 1,
                        'start_line': node.start_point[0] + 1,
                        'end_line': node.end_point[0] + 1,
                        'start_byte': node.start_byte,
                        'end_byte': node.end_byte
                    })
            
            for child in node.children:
                traverse(child)
        
        traverse(struct_node)
        return fields
    
    def extract_includes(self, node, content):
        """æå–é¢„å¤„ç†åŒ…å«æŒ‡ä»¤"""
        includes = []
        
        def traverse(node):
            if node.type == 'preproc_include':
                include_text = content[node.start_byte:node.end_byte].strip()
                includes.append({
                    'text': include_text,
                    'line': node.start_point[0] + 1,
                    'start_line': node.start_point[0] + 1,
                    'end_line': node.end_point[0] + 1,
                    'start_byte': node.start_byte,
                    'end_byte': node.end_byte
                })
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        return includes
    
    def extract_global_variables(self, node, content, root_node):
        """æå–å…¨å±€å˜é‡å£°æ˜ï¼ŒåŒ…æ‹¬é™æ€å¸¸é‡å’Œè®¡ç®—å‹å˜é‡"""
        variables = []
        
        def is_function_declaration(text):
            """æ›´ç²¾ç¡®åœ°åˆ¤æ–­æ˜¯å¦ä¸ºå‡½æ•°å£°æ˜"""
            # ç®€å•çš„å¯å‘å¼è§„åˆ™ï¼š
            # 1. å¦‚æœåŒ…å« = å·ï¼Œå¾ˆå¯èƒ½æ˜¯å˜é‡èµ‹å€¼
            if '=' in text:
                return False
            
            # 2. å¦‚æœæœ‰æ‹¬å·ä½†æ²¡æœ‰ç­‰å·ï¼Œä¸”æ‹¬å·å‰æœ‰æ ‡è¯†ç¬¦ï¼Œå¯èƒ½æ˜¯å‡½æ•°
            if '(' in text and ')' in text:
                paren_pos = text.find('(')
                before_paren = text[:paren_pos].strip()
                
                # æ£€æŸ¥æ‹¬å·å‰æœ€åä¸€ä¸ªtokenæ˜¯å¦åƒå‡½æ•°å
                if before_paren:
                    tokens = before_paren.split()
                    if len(tokens) > 0:
                        last_token = tokens[-1].rstrip('*')  # ç§»é™¤æŒ‡é’ˆæ˜Ÿå·
                        # å¦‚æœæœ€åä¸€ä¸ªtokenæ˜¯æœ‰æ•ˆçš„æ ‡è¯†ç¬¦ï¼Œä¸”æ•´è¡Œä¸åŒ…å«èµ‹å€¼
                        if last_token.replace('_', '').isalnum() and last_token[0].isalpha():
                            # æ£€æŸ¥æ‹¬å·åæ˜¯å¦ç›´æ¥è·Ÿåˆ†å·ï¼ˆå‡½æ•°å£°æ˜ï¼‰
                            after_paren = text[text.rfind(')') + 1:].strip()
                            if after_paren == ';' or after_paren.startswith(';'):
                                return True
            
            return False
        
        def traverse(node):
            if (node.type == 'declaration' and 
                node.parent and node.parent.type == 'translation_unit'):
                # è¿™æ˜¯ä¸€ä¸ªé¡¶çº§å£°æ˜
                var_text = content[node.start_byte:node.end_byte].strip()
                if (var_text and 
                    not var_text.startswith('typedef') and
                    not is_function_declaration(var_text)):
                    
                    # æå–å‰ç½®æ³¨é‡Š
                    comment = self.extract_preceding_comment(node, root_node, content)
                    
                    var_info = {
                        'text': var_text,
                        'line': node.start_point[0] + 1,
                        'start_line': node.start_point[0] + 1,
                        'end_line': node.end_point[0] + 1,
                        'start_byte': node.start_byte,
                        'end_byte': node.end_byte,
                        'comment': comment if comment else ''
                    }
                        
                    variables.append(var_info)
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        return variables
    
    def extract_typedefs(self, node, content, root_node):
        """æå–typedefå®šä¹‰"""
        typedefs = []
        
        def traverse(node):
            if node.type == 'type_definition':
                # æå–å®Œæ•´çš„typedefå®šä¹‰
                typedef_text = content[node.start_byte:node.end_byte].strip()
                if typedef_text:
                    # å°è¯•æå–typedefçš„åç§°
                    typedef_name = self.extract_typedef_name(node, content)
                    
                    # æå–å‰ç½®æ³¨é‡Š
                    comment = self.extract_preceding_comment(node, root_node, content)
                    
                    typedef_info = {
                        'text': typedef_text,
                        'name': typedef_name if typedef_name else '',
                        'line': node.start_point[0] + 1,
                        'start_line': node.start_point[0] + 1,
                        'end_line': node.end_point[0] + 1,
                        'start_byte': node.start_byte,
                        'end_byte': node.end_byte,
                        'comment': comment if comment else ''
                    }
                        
                    typedefs.append(typedef_info)
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        return typedefs
    
    def extract_typedef_name(self, typedef_node, content):
        """æå–typedefçš„åç§°"""
        try:
            # å¯¹äºå‡½æ•°æŒ‡é’ˆtypedefï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            # ä¾‹å¦‚: typedef unsigned int (*BloomFilterHashFunc)(BloomFilterValue data);
            # çœŸæ­£çš„typedefåç§°æ˜¯æ‹¬å·ä¸­çš„æ ‡è¯†ç¬¦
            
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°æŒ‡é’ˆtypedef
            typedef_text = content[typedef_node.start_byte:typedef_node.end_byte]
            if '(*' in typedef_text and ')(' in typedef_text:
                # è¿™æ˜¯å‡½æ•°æŒ‡é’ˆtypedefï¼Œæå–æ‹¬å·ä¸­çš„åç§°
                import re
                # åŒ¹é… (*åç§°) æ¨¡å¼
                match = re.search(r'\(\s*\*\s*(\w+)\s*\)', typedef_text)
                if match:
                    return match.group(1)
            
            # å¯¹äºæ™®é€štypedefï¼ŒæŸ¥æ‰¾æ‰€æœ‰æ ‡è¯†ç¬¦
            identifiers = []
            type_identifiers = []
            
            def find_identifiers(node):
                if node.type == 'identifier':
                    identifiers.append(content[node.start_byte:node.end_byte])
                elif node.type == 'type_identifier':
                    type_identifiers.append(content[node.start_byte:node.end_byte])
                for child in node.children:
                    find_identifiers(child)
            
            find_identifiers(typedef_node)
            
            # å¯¹äºæ™®é€štypedefï¼Œtypedefåç§°é€šå¸¸æ˜¯æœ€åä¸€ä¸ªidentifieræˆ–type_identifier
            # ä¼˜å…ˆä½¿ç”¨identifierï¼ˆæ–°å®šä¹‰çš„ç±»å‹åï¼‰ï¼Œç„¶åä½¿ç”¨type_identifier
            if identifiers:
                return identifiers[-1]
            elif type_identifiers:
                return type_identifiers[-1]
            else:
                return None
        except:
            return None
    
    def extract_macros(self, node, content, root_node):
        """æå–å®å®šä¹‰ (#define)"""
        macros = []
        
        def traverse(node):
            if node.type == 'preproc_def':
                # æå–å®Œæ•´çš„å®å®šä¹‰
                macro_text = content[node.start_byte:node.end_byte].strip()
                if macro_text:
                    # æå–å®åç§°
                    macro_name = self.extract_macro_name(node, content)
                    
                    # æå–å‰ç½®æ³¨é‡Š
                    comment = self.extract_preceding_comment(node, root_node, content)
                    
                    macro_info = {
                        'text': macro_text,
                        'name': macro_name if macro_name else '',
                        'line': node.start_point[0] + 1,
                        'start_line': node.start_point[0] + 1,
                        'end_line': node.end_point[0] + 1,
                        'start_byte': node.start_byte,
                        'end_byte': node.end_byte,
                        'comment': comment if comment else ''
                    }
                        
                    macros.append(macro_info)
            # ä¹Ÿæ£€æŸ¥å…¶ä»–å¯èƒ½çš„é¢„å¤„ç†å™¨èŠ‚ç‚¹ç±»å‹
            elif node.type in ['preproc_function_def', 'preproc_call']:
                macro_text = content[node.start_byte:node.end_byte].strip()
                if macro_text.startswith('#define'):
                    # æå–å®åç§°
                    macro_name = self.extract_macro_name(node, content)
                    
                    # æå–å‰ç½®æ³¨é‡Š
                    comment = self.extract_preceding_comment(node, root_node, content)
                    
                    macro_info = {
                        'text': macro_text,
                        'name': macro_name if macro_name else '',
                        'line': node.start_point[0] + 1,
                        'start_line': node.start_point[0] + 1,
                        'end_line': node.end_point[0] + 1,
                        'start_byte': node.start_byte,
                        'end_byte': node.end_byte,
                        'comment': comment if comment else ''
                    }
                        
                    macros.append(macro_info)
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        
        return macros
    
    def extract_macro_name(self, macro_node, content):
        """æå–å®å®šä¹‰çš„åç§°"""
        try:
            # å®çš„åç§°æ˜¯#defineåçš„ç¬¬ä¸€ä¸ªidentifier
            for child in macro_node.children:
                if child.type == 'identifier':
                    return content[child.start_byte:child.end_byte]
            return None
        except:
            return None
    
    def extract_enums(self, node, content, root_node):
        """æå–æšä¸¾å®šä¹‰"""
        enums = []
        
        def traverse(node):
            if node.type == 'enum_specifier':
                enum_info = self.parse_enum(node, content, root_node)
                if enum_info:
                    enums.append(enum_info)
            
            for child in node.children:
                traverse(child)
        
        traverse(node)
        return enums
    
    def parse_enum(self, node, content, root_node):
        """è§£ææšä¸¾å®šä¹‰"""
        try:
            enum_name = None
            enumerators = []
            
            for child in node.children:
                if child.type == 'type_identifier':
                    enum_name = content[child.start_byte:child.end_byte]
                elif child.type == 'enumerator_list':
                    for enumerator_child in child.children:
                        if enumerator_child.type == 'enumerator':
                            enumerator_text = content[enumerator_child.start_byte:enumerator_child.end_byte]
                            enumerators.append(enumerator_text.strip())
            
            # æå–å®Œæ•´çš„æšä¸¾å®šä¹‰
            full_definition = content[node.start_byte:node.end_byte]
            
            # æå–å‰ç½®æ³¨é‡Š
            comment = self.extract_preceding_comment(node, root_node, content)
            
            result = {
                'name': enum_name if enum_name else 'anonymous',
                'enumerators': enumerators,
                'start_line': node.start_point[0] + 1,
                'end_line': node.end_point[0] + 1,
                'start_byte': node.start_byte,
                'end_byte': node.end_byte,
                'full_definition': full_definition,
                'comment': comment if comment else ''
            }
                
            return result
        except:
            pass
        return None
    
    def extract_preceding_comment(self, target_node, root_node, content):
        """ä½¿ç”¨Tree-sitteræå–ç›®æ ‡èŠ‚ç‚¹å‰é¢çš„æ³¨é‡Š"""
        try:
            # æ”¶é›†æ‰€æœ‰æ³¨é‡ŠèŠ‚ç‚¹
            comment_nodes = []
            
            def collect_comments(node):
                if node.type == 'comment':
                    comment_nodes.append(node)
                for child in node.children:
                    collect_comments(child)
            
            collect_comments(root_node)
            
            # æ‰¾åˆ°ç›®æ ‡èŠ‚ç‚¹å‰é¢æœ€è¿‘çš„æ³¨é‡Š
            target_start_line = target_node.start_point[0]
            preceding_comments = []
            
            for comment in comment_nodes:
                comment_end_line = comment.end_point[0]
                # æ³¨é‡Šå¿…é¡»åœ¨ç›®æ ‡èŠ‚ç‚¹ä¹‹å‰ï¼Œä¸”è·ç¦»ä¸èƒ½å¤ªè¿œï¼ˆæœ€å¤š3è¡Œç©ºè¡Œï¼‰
                if comment_end_line < target_start_line and (target_start_line - comment_end_line) <= 3:
                    preceding_comments.append(comment)
            
            if not preceding_comments:
                return None
            
            # æŒ‰è¡Œå·æ’åºï¼Œå–æœ€æ¥è¿‘çš„è¿ç»­æ³¨é‡Šå—
            preceding_comments.sort(key=lambda x: x.start_point[0])
            
            # æ‰¾åˆ°æœ€åä¸€ä¸ªè¿ç»­çš„æ³¨é‡Šå—
            final_comments = []
            if preceding_comments:
                # ä»æœ€åä¸€ä¸ªæ³¨é‡Šå¼€å§‹ï¼Œå‘å‰æŸ¥æ‰¾è¿ç»­çš„æ³¨é‡Š
                last_comment = preceding_comments[-1]
                final_comments.append(last_comment)
                
                for i in range(len(preceding_comments) - 2, -1, -1):
                    current_comment = preceding_comments[i]
                    # å¦‚æœå½“å‰æ³¨é‡Šå’Œä¸‹ä¸€ä¸ªæ³¨é‡Šä¹‹é—´åªæœ‰å¾ˆå°‘è¡Œæ•°ï¼ˆ<=2ï¼‰ï¼Œè®¤ä¸ºæ˜¯è¿ç»­çš„
                    if (final_comments[0].start_point[0] - current_comment.end_point[0]) <= 2:
                        final_comments.insert(0, current_comment)
                    else:
                        break
            
            # æå–æ³¨é‡Šå†…å®¹å¹¶æ¸…ç†
            if final_comments:
                comment_texts = []
                for comment in final_comments:
                    comment_text = content[comment.start_byte:comment.end_byte]
                    # æ¸…ç†æ³¨é‡Šæ ‡è®°
                    if comment_text.startswith('//'):
                        clean_text = comment_text[2:].strip()
                    elif comment_text.startswith('/*') and comment_text.endswith('*/'):
                        clean_text = comment_text[2:-2].strip()
                    else:
                        clean_text = comment_text.strip()
                    
                    if clean_text:
                        comment_texts.append(clean_text)
                
                return ' '.join(comment_texts) if comment_texts else None
            
            return None
            
        except Exception:
            return None
    
    def count_nodes(self, node):
        """ç»Ÿè®¡ASTèŠ‚ç‚¹æ•°é‡"""
        count = 1
        for child in node.children:
            count += self.count_nodes(child)
        return count
    
    def analyze_project(self, project_path=None):
        """åˆ†ææ•´ä¸ªCå·¥ç¨‹"""
        if project_path is None:
            project_path = self.project_root
        project_path = Path(project_path).resolve()

        print(f"ğŸ” å¼€å§‹åˆ†æCå·¥ç¨‹: {project_path}")
        print("=" * 60)
        
        # æŸ¥æ‰¾æ‰€æœ‰Cå’ŒHæ–‡ä»¶
        c_files, h_files = self.find_c_files(project_path)
        all_files = c_files + h_files
        
        print(f"ğŸ“ å‘ç°æ–‡ä»¶:")
        print(f"   â€¢ Cæ–‡ä»¶: {len(c_files)}ä¸ª")
        print(f"   â€¢ Hæ–‡ä»¶: {len(h_files)}ä¸ª")
        print(f"   â€¢ æ€»è®¡: {len(all_files)}ä¸ª")
        print()
        
        if not all_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•C/Hæ–‡ä»¶")
            return
        
        # é€ä¸ªè§£ææ–‡ä»¶
        print("ğŸ”„ æ­£åœ¨è§£ææ–‡ä»¶...")
        successful_parses = 0
        total_functions = 0
        total_structs = 0
        total_typedefs = 0
        total_macros = 0
        total_enums = 0
        
        for i, file_path in enumerate(all_files):
            rel_for_display = to_relative_path(file_path)
            print(f"   [{i+1:3d}/{len(all_files)}] {rel_for_display}")

            result = self.parse_single_file(file_path)
            self.analysis_results[result['file_path']] = result
            
            if result['parse_success']:
                successful_parses += 1
                total_functions += len(result['functions'])
                total_structs += len(result['structs'])
                total_typedefs += len(result['typedefs'])
                total_macros += len(result['macros'])
                total_enums += len(result['enums'])
        
        print()
        print("ğŸ“Š åˆ†æç»“æœç»Ÿè®¡:")
        print(f"   â€¢ æˆåŠŸè§£æ: {successful_parses}/{len(all_files)} æ–‡ä»¶")
        print(f"   â€¢ æ€»å‡½æ•°æ•°: {total_functions}")
        print(f"   â€¢ æ€»ç»“æ„ä½“: {total_structs}")
        print(f"   â€¢ æ€»typedef: {total_typedefs}")
        print(f"   â€¢ æ€»å®å®šä¹‰: {total_macros}")
        print(f"   â€¢ æ€»æšä¸¾: {total_enums}")
        print()

        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        self.display_detailed_results(project_path)
    
    def display_detailed_results(self, project_path):
        """æ˜¾ç¤ºè¯¦ç»†çš„åˆ†æç»“æœ"""
        print("ğŸ“‹ è¯¦ç»†åˆ†æç»“æœ:")
        print("-" * 60)
        
        for file_path, result in self.analysis_results.items():
            relative_path = file_path
            
            if result['parse_success']:
                print(f"\nğŸ“„ {relative_path}")
                print(f"   â€¢ å‡½æ•°: {len(result['functions'])}ä¸ª")
                print(f"   â€¢ ç»“æ„ä½“: {len(result['structs'])}ä¸ª")
                print(f"   â€¢ typedef: {len(result['typedefs'])}ä¸ª")
                print(f"   â€¢ åŒ…å«æŒ‡ä»¤: {len(result['includes'])}ä¸ª")
                print(f"   â€¢ ASTèŠ‚ç‚¹: {result['total_nodes']}ä¸ª")
                
                # æ˜¾ç¤ºå‡½æ•°åˆ—è¡¨
                if result['functions']:
                    print("   ğŸ“ å‡½æ•°åˆ—è¡¨:")
                    for func in result['functions'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"      - {func['name']}() [{func['type']}]")
                    if len(result['functions']) > 5:
                        print(f"      ... è¿˜æœ‰{len(result['functions'])-5}ä¸ªå‡½æ•°")
                
                # æ˜¾ç¤ºç»“æ„ä½“åˆ—è¡¨
                if result['structs']:
                    print("   ğŸ“¦ ç»“æ„ä½“åˆ—è¡¨:")
                    for struct in result['structs']:
                        print(f"      - struct {struct['name']}")
                
                # æ˜¾ç¤ºtypedefåˆ—è¡¨
                if result['typedefs']:
                    print("   ğŸ·ï¸  typedefåˆ—è¡¨:")
                    for typedef in result['typedefs'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        name = typedef['name'] if typedef['name'] else '?'
                        print(f"      - {name}")
                    if len(result['typedefs']) > 3:
                        print(f"      ... è¿˜æœ‰{len(result['typedefs'])-3}ä¸ªtypedef")
            else:
                print(f"\nâŒ {relative_path} - è§£æå¤±è´¥: {result['error']}")
        
        print("\nâœ… Cå·¥ç¨‹åˆ†æå®Œæˆ!")
    
    def save_results(self, output_file):
        """ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Cé¡¹ç›®åˆ†æå™¨')
    parser.add_argument('project_path', nargs='?', default=None,
                        help='è¦åˆ†æçš„Cé¡¹ç›®è·¯å¾„ï¼ˆé»˜è®¤è¯»å–é…ç½®æ–‡ä»¶ï¼‰')
    parser.add_argument('-o', '--output', default="output/c_project_analysis.json",
                       help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = CProjectAnalyzer()
    
    if args.project_path:
        project_path = Path(args.project_path).resolve()
        if not project_path.exists():
            print(f"âŒ å·¥ç¨‹è·¯å¾„ä¸å­˜åœ¨: {project_path}")
            print("è¯·æä¾›æ­£ç¡®çš„Cå·¥ç¨‹è·¯å¾„")
            return
    else:
        project_path = analyzer.project_root

    print(f"ğŸ” å¼€å§‹åˆ†æé¡¹ç›®: {project_path}")
    analyzer.analyze_project(project_path)

    output_path = Path(args.output)
    if not output_path.is_absolute():
        output_path = Path(__file__).resolve().parent / output_path
    output_path.parent.mkdir(parents=True, exist_ok=True)
    analyzer.save_results(str(output_path))

if __name__ == "__main__":
    main()
