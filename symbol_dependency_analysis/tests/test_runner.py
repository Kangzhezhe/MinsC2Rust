#!/usr/bin/env python3
"""
æµ‹è¯•è¿è¡Œå™¨ï¼šè¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
"""

import sys
import os
import time
import importlib.util
import subprocess

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
    test_modules = [
        'test_symbols',
        'test_binn_dependencies', 
        'test_macro_dependencies',
        'test_type_dependencies',
        'test_function_dependencies',
        'test_scope_analysis'
    ]
    
    print("ğŸ§ª å¼€å§‹è¿è¡Œç¬¦å·ä¾èµ–åˆ†æå™¨æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    total_start_time = time.time()
    passed_tests = 0
    failed_tests = 0
    
    for i, module_name in enumerate(test_modules, 1):
        print(f"\n[{i}/{len(test_modules)}] è¿è¡Œ {module_name}")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # ä½¿ç”¨subprocessè¿è¡Œæµ‹è¯•ï¼Œè¿™æ ·æ›´å®‰å…¨
            result = subprocess.run([sys.executable, f"{module_name}.py"], 
                                  capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                passed_tests += 1
                print("âœ… æµ‹è¯•é€šè¿‡")
            else:
                failed_tests += 1
                print(f"âŒ æµ‹è¯•å¤±è´¥")
                if result.stderr:
                    print(f"é”™è¯¯: {result.stderr.strip()}")
                
        except subprocess.TimeoutExpired:
            failed_tests += 1
            print("âŒ æµ‹è¯•è¶…æ—¶")
                
        except Exception as e:
            failed_tests += 1
            print(f"âŒ æ–­è¨€å¤±è´¥: {e}")
            continue
        except Exception as e:
            failed_tests += 1
            print(f"âŒ æµ‹è¯• {module_name} å¤±è´¥: {e}")
            continue
        
        end_time = time.time()
        print(f"â±ï¸  è€—æ—¶: {end_time - start_time:.2f}s")
    
    total_end_time = time.time()
    
    print("\n" + "=" * 60)
    print(f"ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"âœ… é€šè¿‡: {passed_tests}")
    print(f"âŒ å¤±è´¥: {failed_tests}")
    print(f"ğŸ“Š æˆåŠŸç‡: {passed_tests/(passed_tests+failed_tests)*100:.1f}%")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_end_time - total_start_time:.2f}s")
    
    return failed_tests == 0

def run_quick_tests():
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆåªæµ‹è¯•åŸºç¡€åŠŸèƒ½ï¼‰"""
    print("ğŸš€ è¿è¡Œå¿«é€Ÿæµ‹è¯•")
    print("=" * 40)
    
    # åªè¿è¡Œæœ€é‡è¦çš„æµ‹è¯•
    important_tests = ['test_symbols', 'test_binn_dependencies']
    
    passed = 0
    failed = 0
    
    for test_name in important_tests:
        print(f"\nâ–¶ï¸  è¿è¡Œ {test_name}")
        try:
            module = __import__(test_name)
            if hasattr(module, '__main__'):
                exec(open(f"{test_name}.py").read())
            print(f"âœ… {test_name} é€šè¿‡")
            passed += 1
        except AssertionError as e:
            print(f"âŒ {test_name} æ–­è¨€å¤±è´¥: {e}")
            failed += 1
        except Exception as e:
            print(f"âŒ {test_name} å¤±è´¥: {e}")
            failed += 1
    
    print(f"\nğŸ“Š å¿«é€Ÿæµ‹è¯•ç»“æœ: {passed} é€šè¿‡, {failed} å¤±è´¥")
    return failed == 0

def run_specific_test(test_name):
    """è¿è¡Œç‰¹å®šçš„æµ‹è¯•"""
    print(f"ğŸ¯ è¿è¡Œç‰¹å®šæµ‹è¯•: {test_name}")
    print("=" * 40)
    
    try:
        exec(open(f"{test_name}.py").read())
        print(f"âœ… {test_name} å®Œæˆ")
        return True
    except AssertionError as e:
        print(f"âŒ {test_name} æ–­è¨€å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ {test_name} å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ç¬¦å·ä¾èµ–åˆ†æå™¨æµ‹è¯•è¿è¡Œå™¨')
    parser.add_argument('--quick', action='store_true', help='è¿è¡Œå¿«é€Ÿæµ‹è¯•')
    parser.add_argument('--test', type=str, help='è¿è¡Œç‰¹å®šæµ‹è¯•')
    
    args = parser.parse_args()
    
    if args.quick:
        run_quick_tests()
    elif args.test:
        run_specific_test(args.test)
    else:
        run_all_tests()
