#!/usr/bin/env python3
"""
Cä»£ç ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨
åŸºäºtree-sitter ASTå’Œc_project_analysis.jsonæ„å»ºç¬¦å·ä¾èµ–å›¾
"""

import json
import os
import tree_sitter_c as ts_c
from tree_sitter import Language, Parser, Node
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum
import re
from pathlib import Path

class SymbolType(Enum):
    """ç¬¦å·ç±»å‹æšä¸¾"""
    FUNCTION = "functions"
    STRUCT = "structs"
    TYPEDEF = "typedefs"
    VARIABLE = "variables"
    MACRO = "macros"
    ENUM = "enums"

class DependencyType(Enum):
    """ä¾èµ–ç±»å‹æšä¸¾"""
    FUNCTION_CALL = "function_call"      # å‡½æ•°è°ƒç”¨
    TYPE_REFERENCE = "type_reference"    # ç±»å‹å¼•ç”¨
    VARIABLE_USE = "variable_use"        # å˜é‡ä½¿ç”¨
    MACRO_USE = "macro_use"              # å®ä½¿ç”¨
    ENUM_USE = "enum_use"                # æšä¸¾ä½¿ç”¨
    STRUCT_MEMBER = "struct_member"      # ç»“æ„ä½“æˆå‘˜è®¿é—®

@dataclass
class Symbol:
    """ç¬¦å·ä¿¡æ¯"""
    name: str
    symbol_type: SymbolType
    file_path: str
    start_line: int = 0
    end_line: int = 0
    definition: str = ""
    
    def __hash__(self):
        return hash((self.name, self.symbol_type.value, self.file_path))
    
    def __eq__(self, other):
        if not isinstance(other, Symbol):
            return False
        return (self.name == other.name and 
                self.symbol_type == other.symbol_type and 
                self.file_path == other.file_path)

@dataclass
class Dependency:
    """ä¾èµ–å…³ç³»"""
    source_symbol: Symbol
    target_symbol: Symbol
    dependency_type: DependencyType
    location: Tuple[int, int] = (0, 0)  # (start_line, end_line)
    context: str = ""  # ä¾èµ–å‘ç”Ÿçš„ä¸Šä¸‹æ–‡ä»£ç 

@dataclass
class SymbolDependencyGraph:
    """ç¬¦å·ä¾èµ–å›¾"""
    symbols: Dict[str, Symbol] = field(default_factory=dict)
    dependencies: List[Dependency] = field(default_factory=list)
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        self._dependency_set: Set[str] = set()  # ç”¨äºæ£€æµ‹é‡å¤ä¾èµ–
    
    def add_symbol(self, symbol: Symbol):
        """æ·»åŠ ç¬¦å·"""
        key = f"{symbol.name}:{symbol.symbol_type.value}:{symbol.file_path}"
        self.symbols[key] = symbol
    
    def add_dependency(self, dependency: Dependency):
        """æ·»åŠ ä¾èµ–å…³ç³»ï¼ˆè‡ªåŠ¨å»é‡ï¼‰"""
        # åˆ›å»ºä¾èµ–å…³ç³»çš„å”¯ä¸€æ ‡è¯†ï¼ˆä¸åŒ…æ‹¬å…·ä½“çš„ç¬¦å·å®ä¾‹å’Œä½ç½®ï¼‰
        dep_signature = (
            dependency.source_symbol.name,
            dependency.source_symbol.symbol_type.value,
            dependency.source_symbol.file_path,
            dependency.target_symbol.name,
            dependency.target_symbol.symbol_type.value,
            dependency.target_symbol.file_path,
            dependency.dependency_type.value
        )
        
        # åªæ·»åŠ ä¸é‡å¤çš„ä¾èµ–å…³ç³»
        dep_key = str(dep_signature)
        if not hasattr(self, '_dependency_set'):
            self._dependency_set = set()
            
        if dep_key not in self._dependency_set:
            self.dependencies.append(dependency)
            self._dependency_set.add(dep_key)
            return True  # æˆåŠŸæ·»åŠ 
        return False  # é‡å¤ï¼Œæœªæ·»åŠ 
    
    def get_symbol_dependencies(self, symbol_name: str, symbol_type: SymbolType = None) -> List[Dependency]:
        """è·å–æŒ‡å®šç¬¦å·çš„æ‰€æœ‰ä¾èµ–"""
        dependencies = []
        for dep in self.dependencies:
            if dep.source_symbol.name == symbol_name:
                if symbol_type is None or dep.source_symbol.symbol_type == symbol_type:
                    dependencies.append(dep)
        return dependencies
    
    def get_symbols_by_type(self, symbol_type: SymbolType) -> List[Symbol]:
        """æ ¹æ®ç±»å‹è·å–ç¬¦å·"""
        return [symbol for symbol in self.symbols.values() 
                if symbol.symbol_type == symbol_type]
    
    def get_symbol_dependents(self, symbol_name: str, symbol_type: SymbolType = None) -> List[Dependency]:
        """è·å–ä¾èµ–æŒ‡å®šç¬¦å·çš„æ‰€æœ‰ä¾èµ–å…³ç³»ï¼ˆè¢«ä¾èµ–ï¼‰"""
        dependents = []
        for dep in self.dependencies:
            if dep.target_symbol.name == symbol_name:
                if symbol_type is None or dep.target_symbol.symbol_type == symbol_type:
                    dependents.append(dep)
        return dependents
    
    def get_all_related_symbols(self, symbol_name: str, max_depth: int = 2) -> Set[str]:
        """è·å–ä¸æŒ‡å®šç¬¦å·ç›¸å…³çš„æ‰€æœ‰ç¬¦å·ï¼ˆåŒ…æ‹¬ä¾èµ–å’Œè¢«ä¾èµ–ï¼‰"""
        related = set()
        to_visit = [(symbol_name, 0)]
        visited = set()
        
        while to_visit:
            current_symbol, depth = to_visit.pop(0)
            if current_symbol in visited or depth > max_depth:
                continue
            
            visited.add(current_symbol)
            related.add(current_symbol)
            
            if depth < max_depth:
                # æ·»åŠ ä¾èµ–çš„ç¬¦å·
                deps = self.get_symbol_dependencies(current_symbol)
                for dep in deps:
                    if dep.target_symbol.name not in visited:
                        to_visit.append((dep.target_symbol.name, depth + 1))
                
                # æ·»åŠ è¢«ä¾èµ–çš„ç¬¦å·
                dependents = self.get_symbol_dependents(current_symbol)
                for dep in dependents:
                    if dep.source_symbol.name not in visited:
                        to_visit.append((dep.source_symbol.name, depth + 1))
        
        return related

class SymbolDependencyAnalyzer:
    """ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨"""
    
    def __init__(self, analysis_json_path: str):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.analysis_json_path = analysis_json_path
        self.C_LANGUAGE = Language(ts_c.language())
        self.parser = Parser(self.C_LANGUAGE)
        
        # åŠ è½½åˆ†æç»“æœ
        with open(analysis_json_path, 'r', encoding='utf-8') as f:
            self.analysis_data = json.load(f)
        
        # åˆå§‹åŒ–ä¾èµ–å›¾
        self.dependency_graph = SymbolDependencyGraph()
        
        # ç¬¦å·æ³¨å†Œè¡¨ï¼šå­˜å‚¨æ‰€æœ‰å·²çŸ¥ç¬¦å·
        self.symbol_registry: Dict[str, List[Symbol]] = {}
        
        # Cè¯­è¨€å…³é”®å­—å’Œå†…ç½®ç±»å‹ï¼Œéœ€è¦æ’é™¤
        self.c_keywords = {
            'auto', 'break', 'case', 'char', 'const', 'continue', 'default', 'do',
            'double', 'else', 'enum', 'extern', 'float', 'for', 'goto', 'if',
            'int', 'long', 'register', 'return', 'short', 'signed', 'sizeof', 'static',
            'struct', 'switch', 'typedef', 'union', 'unsigned', 'void', 'volatile', 'while',
            # C99/C11 keywords
            'inline', 'restrict', '_Bool', '_Complex', '_Imaginary',
            # Common types
            'size_t', 'ssize_t', 'ptrdiff_t', 'NULL'
        }
        
        # å†…ç½®å‡½æ•°ï¼Œéœ€è¦æ’é™¤
        self.builtin_functions = {
            'malloc', 'free', 'calloc', 'realloc', 'printf', 'scanf', 'strlen',
            'strcpy', 'strcmp', 'strncmp', 'strcat', 'memcpy', 'memset', 'memcmp'
        }
    
    def build_symbol_registry(self):
        """æ„å»ºç¬¦å·æ³¨å†Œè¡¨"""
        print("æ„å»ºç¬¦å·æ³¨å†Œè¡¨...")
        
        for file_path, file_data in self.analysis_data.items():
            if not file_data.get('parse_success', False):
                continue
            
            # æ³¨å†Œå„ç§ç±»å‹çš„ç¬¦å·
            for symbol_type in SymbolType:
                symbol_list = file_data.get(symbol_type.value, [])
                for symbol_data in symbol_list:
                    symbol = self._create_symbol_from_data(symbol_data, symbol_type, file_path)
                    if symbol:
                        self.dependency_graph.add_symbol(symbol)
                        
                        # æ·»åŠ åˆ°æ³¨å†Œè¡¨
                        if symbol.name not in self.symbol_registry:
                            self.symbol_registry[symbol.name] = []
                        self.symbol_registry[symbol.name].append(symbol)
        
        print(f"ç¬¦å·æ³¨å†Œè¡¨æ„å»ºå®Œæˆï¼šå…±æ³¨å†Œ {len(self.symbol_registry)} ä¸ªç¬¦å·åç§°")
    
    def _create_symbol_from_data(self, symbol_data: dict, symbol_type: SymbolType, file_path: str) -> Optional[Symbol]:
        """ä»JSONæ•°æ®åˆ›å»ºSymbolå¯¹è±¡"""
        name = symbol_data.get('name', '')
        if not name or name in self.c_keywords:
            return None
        
        symbol = Symbol(
            name=name,
            symbol_type=symbol_type,
            file_path=file_path,
            start_line=symbol_data.get('start_line', 0),
            end_line=symbol_data.get('end_line', 0),
            definition=symbol_data.get('full_definition', '') or symbol_data.get('text', '')
        )
        
        return symbol
    
    def is_valid_symbol_reference(self, name: str, context_node: Node = None) -> bool:
        """åˆ¤æ–­ä¸€ä¸ªåç§°æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ç¬¦å·å¼•ç”¨"""
        if not name or name in self.c_keywords or name in self.builtin_functions:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—æˆ–å­—ç¬¦ä¸²å­—é¢é‡
        if name.isdigit() or (name.startswith('"') and name.endswith('"')):
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ³¨å†Œè¡¨ä¸­
        return name in self.symbol_registry
    
    def extract_dependencies_from_text(self, text: str, source_symbol: Symbol) -> List[Dependency]:
        """ä»æ–‡æœ¬ä¸­æå–ä¾èµ–å…³ç³»"""
        dependencies = []
        
        # ä½¿ç”¨tree-sitterè§£æä»£ç ç‰‡æ®µ
        try:
            tree = self.parser.parse(bytes(text, "utf8"))
            root_node = tree.root_node
            dependencies.extend(self._extract_dependencies_from_ast(root_node, text, source_symbol))
        except Exception as e:
            print(f"è§£æä»£ç ç‰‡æ®µå¤±è´¥ {source_symbol.name}: {e}")
            # å›é€€åˆ°ç®€å•çš„æ–‡æœ¬åŒ¹é…
            dependencies.extend(self._extract_dependencies_by_pattern(text, source_symbol))
        
        return dependencies
    
    def _extract_dependencies_from_ast(self, node: Node, text: str, source_symbol: Symbol) -> List[Dependency]:
        """åŸºäºASTæå–ä¾èµ–å…³ç³»"""
        dependencies = []
        local_variables = set()  # å­˜å‚¨å±€éƒ¨å˜é‡å
        
        def collect_local_variables(node: Node):
            """æ”¶é›†å±€éƒ¨å˜é‡å£°æ˜"""
            if node.type == 'declaration':
                declarator = node.child_by_field_name('declarator')
                if declarator:
                    if declarator.type == 'identifier':
                        var_name = text[declarator.start_byte:declarator.end_byte]
                        local_variables.add(var_name)
                    elif declarator.type == 'init_declarator':
                        declarator_node = declarator.child_by_field_name('declarator')
                        if declarator_node and declarator_node.type == 'identifier':
                            var_name = text[declarator_node.start_byte:declarator_node.end_byte]
                            local_variables.add(var_name)
            
            # å‚æ•°å£°æ˜
            elif node.type == 'parameter_declaration':
                declarator = node.child_by_field_name('declarator')
                if declarator and declarator.type == 'identifier':
                    var_name = text[declarator.start_byte:declarator.end_byte]
                    local_variables.add(var_name)
            
            # é€’å½’æ”¶é›†
            for child in node.children:
                collect_local_variables(child)
        
        def traverse_node(node: Node):
            # å‡½æ•°è°ƒç”¨
            if node.type == 'call_expression':
                func_node = node.child_by_field_name('function')
                if func_node:
                    if func_node.type == 'identifier':
                        func_name = text[func_node.start_byte:func_node.end_byte]
                        if self.is_valid_symbol_reference(func_name) and func_name not in local_variables:
                            dependencies.extend(self._create_dependencies_for_name(
                                func_name, source_symbol, DependencyType.FUNCTION_CALL, func_node
                            ))
                    elif func_node.type == 'field_expression':
                        # å¤„ç†ç»“æ„ä½“æˆå‘˜å‡½æ•°è°ƒç”¨ obj.func()
                        field_node = func_node.child_by_field_name('field')
                        if field_node and field_node.type == 'field_identifier':
                            field_name = text[field_node.start_byte:field_node.end_byte]
                            if self.is_valid_symbol_reference(field_name):
                                dependencies.extend(self._create_dependencies_for_name(
                                    field_name, source_symbol, DependencyType.FUNCTION_CALL, field_node
                                ))
            
            # ç±»å‹å£°æ˜å’Œè½¬æ¢
            elif node.type in ['type_identifier', 'struct_specifier', 'union_specifier', 'enum_specifier']:
                if node.type == 'type_identifier':
                    type_name = text[node.start_byte:node.end_byte]
                    if self.is_valid_symbol_reference(type_name):
                        dependencies.extend(self._create_dependencies_for_name(
                            type_name, source_symbol, DependencyType.TYPE_REFERENCE, node
                        ))
                else:
                    # struct/union/enum å…³é”®å­—åçš„æ ‡è¯†ç¬¦
                    name_node = node.child_by_field_name('name')
                    if name_node and name_node.type == 'type_identifier':
                        type_name = text[name_node.start_byte:name_node.end_byte]
                        if self.is_valid_symbol_reference(type_name):
                            dependencies.extend(self._create_dependencies_for_name(
                                type_name, source_symbol, DependencyType.TYPE_REFERENCE, name_node
                            ))
            
            # å­—æ®µè®¿é—® obj.field
            elif node.type == 'field_expression':
                field_node = node.child_by_field_name('field')
                if field_node and field_node.type == 'field_identifier':
                    field_name = text[field_node.start_byte:field_node.end_byte]
                    if self.is_valid_symbol_reference(field_name):
                        dependencies.extend(self._create_dependencies_for_name(
                            field_name, source_symbol, DependencyType.STRUCT_MEMBER, field_node
                        ))
            
            # é¢„å¤„ç†æŒ‡ä»¤ (å®ä½¿ç”¨)
            elif node.type == 'preproc_defined' or node.type == 'preproc_call':
                if node.type == 'preproc_call':
                    directive_node = node.child_by_field_name('directive')
                    if directive_node and directive_node.type == 'preproc_directive':
                        directive_name = text[directive_node.start_byte:directive_node.end_byte]
                        if self.is_valid_symbol_reference(directive_name):
                            dependencies.extend(self._create_dependencies_for_name(
                                directive_name, source_symbol, DependencyType.MACRO_USE, directive_node
                            ))
            
            # sizeof è¡¨è¾¾å¼
            elif node.type == 'sizeof_expression':
                type_node = node.child_by_field_name('type')
                if type_node:
                    if type_node.type == 'type_identifier':
                        type_name = text[type_node.start_byte:type_node.end_byte]
                        if self.is_valid_symbol_reference(type_name):
                            dependencies.extend(self._create_dependencies_for_name(
                                type_name, source_symbol, DependencyType.TYPE_REFERENCE, type_node
                            ))
                    elif type_node.type == 'parenthesized_expression':
                        inner_node = type_node.children[1] if len(type_node.children) > 1 else None
                        if inner_node and inner_node.type == 'type_identifier':
                            type_name = text[inner_node.start_byte:inner_node.end_byte]
                            if self.is_valid_symbol_reference(type_name):
                                dependencies.extend(self._create_dependencies_for_name(
                                    type_name, source_symbol, DependencyType.TYPE_REFERENCE, inner_node
                                ))
            
            # æ ‡è¯†ç¬¦å¼•ç”¨ï¼ˆæœ€é€šç”¨çš„æƒ…å†µï¼‰
            elif node.type == 'identifier':
                identifier = text[node.start_byte:node.end_byte]
                if (self.is_valid_symbol_reference(identifier) and 
                    identifier not in local_variables and 
                    not self._is_in_declaration_context(node)):
                    # æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šä¾èµ–ç±»å‹
                    dep_type = self._infer_dependency_type(node, text)
                    dependencies.extend(self._create_dependencies_for_name(
                        identifier, source_symbol, dep_type, node
                    ))
            
            # é€’å½’éå†å­èŠ‚ç‚¹
            for child in node.children:
                traverse_node(child)
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰å±€éƒ¨å˜é‡
        collect_local_variables(node)
        
        # ç„¶åéå†æŸ¥æ‰¾ä¾èµ–
        traverse_node(node)
        return dependencies
    
    def _infer_dependency_type(self, node: Node, text: str) -> DependencyType:
        """æ ¹æ®ASTèŠ‚ç‚¹ä¸Šä¸‹æ–‡æ¨æ–­ä¾èµ–ç±»å‹"""
        identifier = text[node.start_byte:node.end_byte]
        parent = node.parent
        
        if not parent:
            return DependencyType.VARIABLE_USE
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„å®
        if self._is_likely_macro(identifier):
            return DependencyType.MACRO_USE
        
        # å‡½æ•°è°ƒç”¨
        if parent.type == 'call_expression' and parent.child_by_field_name('function') == node:
            return DependencyType.FUNCTION_CALL
        
        # ç±»å‹å£°æ˜æˆ–è½¬æ¢
        if parent.type in ['type_identifier', 'primitive_type', 'cast_expression', 
                          'struct_specifier', 'union_specifier', 'enum_specifier']:
            return DependencyType.TYPE_REFERENCE
        
        # ç»“æ„ä½“æˆå‘˜è®¿é—®
        if parent.type in ['field_expression', 'field_identifier']:
            return DependencyType.STRUCT_MEMBER
        
        # å®ä½¿ç”¨ - æ£€æŸ¥æ˜¯å¦åœ¨å®è°ƒç”¨ä¸­
        if self._is_in_macro_context(node):
            return DependencyType.MACRO_USE
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ³¨å†Œè¡¨ä¸­ç¡®å®šç±»å‹
        if identifier in self.symbol_registry:
            for symbol in self.symbol_registry[identifier]:
                if symbol.symbol_type == SymbolType.FUNCTION:
                    return DependencyType.FUNCTION_CALL
                elif symbol.symbol_type == SymbolType.MACRO:
                    return DependencyType.MACRO_USE
                elif symbol.symbol_type in [SymbolType.STRUCT, SymbolType.TYPEDEF]:
                    return DependencyType.TYPE_REFERENCE
                elif symbol.symbol_type == SymbolType.ENUM:
                    return DependencyType.ENUM_USE
        
        # é»˜è®¤ä¸ºå˜é‡ä½¿ç”¨
        return DependencyType.VARIABLE_USE
    
    def _is_in_declaration_context(self, node: Node) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨å˜é‡å£°æ˜ä¸Šä¸‹æ–‡ä¸­"""
        parent = node.parent
        while parent:
            if parent.type in ['declaration', 'parameter_declaration', 'init_declarator']:
                return True
            parent = parent.parent
        return False
    
    def _is_in_macro_context(self, node: Node) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨å®ä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­"""
        # æ£€æŸ¥æ˜¯å¦åœ¨é¢„å¤„ç†æŒ‡ä»¤ä¸­
        parent = node.parent
        while parent:
            if parent.type in ['preproc_call', 'preproc_defined', 'preproc_ifdef', 'preproc_ifndef']:
                return True
            parent = parent.parent
        return False
    
    def _is_likely_macro(self, name: str) -> bool:
        """åŸºäºå‘½åæ¨¡å¼åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å®"""
        if not name:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¦å·æ³¨å†Œè¡¨ä¸­è¢«æ ‡è®°ä¸ºå®
        if name in self.symbol_registry:
            for symbol in self.symbol_registry[name]:
                if symbol.symbol_type == SymbolType.MACRO:
                    return True
        
        # å¯å‘å¼è§„åˆ™ï¼š
        # 1. å…¨å¤§å†™å­—æ¯åŠ ä¸‹åˆ’çº¿
        if name.isupper() and '_' in name:
            return True
        
        # 2. ä»¥å¸¸è§å®å‰ç¼€å¼€å¤´
        macro_prefixes = ['BINN_', 'API', 'MAX_', 'MIN_', '__', '_']
        for prefix in macro_prefixes:
            if name.startswith(prefix):
                return True
        
        return False
    
    def _extract_dependencies_by_pattern(self, text: str, source_symbol: Symbol) -> List[Dependency]:
        """åŸºäºæ¨¡å¼åŒ¹é…æå–ä¾èµ–å…³ç³»ï¼ˆå›é€€æ–¹æ³•ï¼‰"""
        dependencies = []
        
        # ç®€å•çš„æ ‡è¯†ç¬¦åŒ¹é…
        identifier_pattern = r'\b([a-zA-Z_][a-zA-Z0-9_]*)\b'
        matches = re.finditer(identifier_pattern, text)
        
        for match in matches:
            identifier = match.group(1)
            if self.is_valid_symbol_reference(identifier):
                dependencies.extend(self._create_dependencies_for_name(
                    identifier, source_symbol, DependencyType.VARIABLE_USE, None
                ))
        
        return dependencies
    
    def _create_dependencies_for_name(self, name: str, source_symbol: Symbol, 
                                     dep_type: DependencyType, node: Node = None) -> List[Dependency]:
        """ä¸ºç»™å®šåç§°åˆ›å»ºä¾èµ–å…³ç³»"""
        dependencies = []
        
        if name in self.symbol_registry:
            for target_symbol in self.symbol_registry[name]:
                # é¿å…è‡ªä¾èµ–
                if target_symbol != source_symbol:
                    dependency = Dependency(
                        source_symbol=source_symbol,
                        target_symbol=target_symbol,
                        dependency_type=dep_type,
                        location=(node.start_point[0] + 1, node.end_point[0] + 1) if node else (0, 0)
                    )
                    dependencies.append(dependency)
        
        return dependencies
    
    def analyze_all_dependencies(self):
        """åˆ†ææ‰€æœ‰ç¬¦å·çš„ä¾èµ–å…³ç³»"""
        print("å¼€å§‹åˆ†æç¬¦å·ä¾èµ–å…³ç³»...")
        
        total_symbols = len(self.dependency_graph.symbols)
        analyzed_count = 0
        error_count = 0
        total_found_deps = 0
        total_added_deps = 0
        
        for symbol in self.dependency_graph.symbols.values():
            try:
                # æå–è¯¥ç¬¦å·å®šä¹‰ä¸­çš„ä¾èµ–
                if symbol.definition:
                    dependencies = self.extract_dependencies_from_text(symbol.definition, symbol)
                    total_found_deps += len(dependencies)
                    
                    for dep in dependencies:
                        if self.dependency_graph.add_dependency(dep):
                            total_added_deps += 1
                
                analyzed_count += 1
                
                # æ˜¾ç¤ºè¿›åº¦
                if analyzed_count % 50 == 0 or analyzed_count == total_symbols:
                    progress = (analyzed_count / total_symbols) * 100
                    duplicate_rate = ((total_found_deps - total_added_deps) / max(total_found_deps, 1)) * 100
                    print(f"è¿›åº¦: {analyzed_count}/{total_symbols} ({progress:.1f}%) - "
                          f"å‘ç°: {total_found_deps}, æ·»åŠ : {total_added_deps}, é‡å¤ç‡: {duplicate_rate:.1f}% - é”™è¯¯: {error_count}")
                    
            except Exception as e:
                error_count += 1
                print(f"åˆ†æç¬¦å· {symbol.name} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"ä¾èµ–å…³ç³»åˆ†æå®Œæˆï¼š")
        print(f"  âœ… æˆåŠŸåˆ†æ: {analyzed_count - error_count}/{total_symbols} ä¸ªç¬¦å·")
        print(f"  âŒ åˆ†æé”™è¯¯: {error_count} ä¸ªç¬¦å·")
        print(f"  ğŸ“Š å‘ç°ä¾èµ–: {total_found_deps} ä¸ª")
        print(f"  ğŸ“Š å®é™…æ·»åŠ : {total_added_deps} ä¸ª")
        print(f"  ğŸ”„ å»é‡æ•°é‡: {total_found_deps - total_added_deps} ä¸ª")
        print(f"  ğŸ“ˆ å»é‡ç‡: {((total_found_deps - total_added_deps) / max(total_found_deps, 1)) * 100:.1f}%")
    
    def export_dependencies_to_json(self, output_path: str):
        """å¯¼å‡ºä¾èµ–å…³ç³»åˆ°JSONæ–‡ä»¶"""
        try:
            export_data = {
                'metadata': {
                    'total_symbols': len(self.dependency_graph.symbols),
                    'total_dependencies': len(self.dependency_graph.dependencies),
                    'statistics': self.get_dependency_statistics()
                },
                'symbols': {},
                'dependencies': []
            }
            
            # å¯¼å‡ºç¬¦å·ä¿¡æ¯
            for symbol in self.dependency_graph.symbols.values():
                key = f"{symbol.name}:{symbol.symbol_type.value}:{symbol.file_path}"
                export_data['symbols'][key] = {
                    'name': symbol.name,
                    'type': symbol.symbol_type.value,
                    'file_path': symbol.file_path,
                    'start_line': symbol.start_line,
                    'end_line': symbol.end_line
                }
            
            # å¯¼å‡ºä¾èµ–å…³ç³»
            for dep in self.dependency_graph.dependencies:
                export_data['dependencies'].append({
                    'source': {
                        'name': dep.source_symbol.name,
                        'type': dep.source_symbol.symbol_type.value,
                        'file': dep.source_symbol.file_path
                    },
                    'target': {
                        'name': dep.target_symbol.name,
                        'type': dep.target_symbol.symbol_type.value,
                        'file': dep.target_symbol.file_path
                    },
                    'dependency_type': dep.dependency_type.value,
                    'location': dep.location,
                    'context': dep.context
                })
            
            # å†™å…¥æ–‡ä»¶
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… ä¾èµ–å…³ç³»å·²å¯¼å‡ºåˆ°: {output_path}")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
    
    def generate_dependency_report(self) -> str:
        """ç”Ÿæˆä¾èµ–å…³ç³»æŠ¥å‘Š"""
        stats = self.get_dependency_statistics()
        
        report = []
        report.append("=" * 60)
        report.append("           Cé¡¹ç›®ç¬¦å·ä¾èµ–å…³ç³»åˆ†ææŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        report.append("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        report.append(f"  ç¬¦å·æ€»æ•°: {stats['total_symbols']}")
        report.append(f"  ä¾èµ–æ€»æ•°: {stats['total_dependencies']}")
        report.append("")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ç¬¦å·
        report.append("ğŸ“‹ ç¬¦å·åˆ†å¸ƒ:")
        for symbol_type, count in stats['symbols_by_type'].items():
            report.append(f"  {symbol_type}: {count}")
        report.append("")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ä¾èµ–
        report.append("ğŸ”— ä¾èµ–åˆ†å¸ƒ:")
        for dep_type, count in stats['dependencies_by_type'].items():
            report.append(f"  {dep_type}: {count}")
        report.append("")
        
        # Top 10 æœ€å¤šä¾èµ–çš„ç¬¦å·
        symbol_dep_count = {}
        for dep in self.dependency_graph.dependencies:
            source_name = dep.source_symbol.name
            symbol_dep_count[source_name] = symbol_dep_count.get(source_name, 0) + 1
        
        top_symbols = sorted(symbol_dep_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        report.append("ğŸ” ä¾èµ–æœ€å¤šçš„ç¬¦å· (Top 10):")
        for i, (symbol_name, dep_count) in enumerate(top_symbols, 1):
            report.append(f"  {i:2d}. {symbol_name}: {dep_count} ä¸ªä¾èµ–")
        report.append("")
        
        # Top 10 è¢«ä¾èµ–æœ€å¤šçš„ç¬¦å·
        target_dep_count = {}
        for dep in self.dependency_graph.dependencies:
            target_name = dep.target_symbol.name
            target_dep_count[target_name] = target_dep_count.get(target_name, 0) + 1
        
        top_targets = sorted(target_dep_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        report.append("ğŸ¯ è¢«ä¾èµ–æœ€å¤šçš„ç¬¦å· (Top 10):")
        for i, (symbol_name, dep_count) in enumerate(top_targets, 1):
            report.append(f"  {i:2d}. {symbol_name}: è¢« {dep_count} ä¸ªç¬¦å·ä¾èµ–")
        
        report.append("")
        report.append("=" * 60)
        
        return "\n".join(report)
    
    def get_dependency_statistics(self) -> Dict:
        """è·å–ä¾èµ–å…³ç³»ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_symbols': len(self.dependency_graph.symbols),
            'total_dependencies': len(self.dependency_graph.dependencies),
            'symbols_by_type': {},
            'dependencies_by_type': {}
        }
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ç¬¦å·
        for symbol in self.dependency_graph.symbols.values():
            symbol_type = symbol.symbol_type.value
            stats['symbols_by_type'][symbol_type] = stats['symbols_by_type'].get(symbol_type, 0) + 1
        
        # æŒ‰ç±»å‹ç»Ÿè®¡ä¾èµ–
        for dep in self.dependency_graph.dependencies:
            dep_type = dep.dependency_type.value
            stats['dependencies_by_type'][dep_type] = stats['dependencies_by_type'].get(dep_type, 0) + 1
        
        return stats

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´åŠŸèƒ½"""
    import time
    start_time = time.time()
    
    analyzer = SymbolDependencyAnalyzer('../c_project_analysis.json')
    
    print("=== ç¬¦å·ä¾èµ–å…³ç³»åˆ†æå™¨ ===")
    print("ç¬¬äºŒé˜¶æ®µï¼šå®Œæ•´çš„ä¾èµ–å…³ç³»åˆ†æ")
    print()
    
    # æ„å»ºç¬¦å·æ³¨å†Œè¡¨
    print("1ï¸âƒ£ æ„å»ºç¬¦å·æ³¨å†Œè¡¨...")
    analyzer.build_symbol_registry()
    
    # åˆ†æä¾èµ–å…³ç³»
    print("\n2ï¸âƒ£ åˆ†æç¬¦å·ä¾èµ–å…³ç³»...")
    analyzer.analyze_all_dependencies()
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n3ï¸âƒ£ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report = analyzer.generate_dependency_report()
    print(report)
    
    # å¯¼å‡ºç»“æœ
    print("\n4ï¸âƒ£ å¯¼å‡ºåˆ†æç»“æœ...")
    analyzer.export_dependencies_to_json('symbol_dependencies.json')
    
    # æ€§èƒ½ç»Ÿè®¡
    end_time = time.time()
    print(f"\nâ±ï¸ æ€»ç”¨æ—¶: {end_time - start_time:.2f} ç§’")

if __name__ == "__main__":
    main()
